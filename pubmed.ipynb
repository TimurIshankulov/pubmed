{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:37:22.914315Z",
     "start_time": "2020-08-02T21:37:22.890331Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:37:24.559625Z",
     "start_time": "2020-08-02T21:37:23.066214Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from IPython.display import clear_output\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:37:24.570668Z",
     "start_time": "2020-08-02T21:37:24.559625Z"
    }
   },
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) ' + \\\n",
    "                         'Chrome/84.0.4147.105 Safari/537.36'\n",
    "}\n",
    "\n",
    "api_key     = '2839ed49187b099ec3d13cc079fc3ca0fc09'\n",
    "max_results = 5000\n",
    "retmode     = 'xml'\n",
    "\n",
    "dbs = ['pmc', 'pubmed', 'database']\n",
    "for db in dbs:\n",
    "    if not os.path.exists(db):\n",
    "        os.makedirs(db)\n",
    "\n",
    "files_stoplist = ['6796246', '4669991', '4212306', '4070603', '4912513', '2799065', '5042924', '6032109', '5042923',\n",
    "                  '6555104', '5724662', '5493079', '6117636', '5933288', '6763540', '6493311', '6737605', '5637785']\n",
    "\n",
    "url_pubmed_to_pmc = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi'\n",
    "url_fetch         = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi'\n",
    "url_search        = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:37:24.586658Z",
     "start_time": "2020-08-02T21:37:24.570668Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_pub_date(subroot, pub_type):\n",
    "    \"\"\"Returns parsed publication date from given ET <subroot>\"\"\"\n",
    "    pub_date = np.NaN\n",
    "    pub_dates = subroot.findall('pub-date')\n",
    "    for pub_record in pub_dates:\n",
    "        if (pub_record.attrib.get('pub-type', '') == pub_type or\n",
    "            pub_record.attrib.get('date-type', '') == 'pub'):\n",
    "            day = pub_record.find('day')\n",
    "            month = pub_record.find('month')\n",
    "            year = pub_record.find('year')\n",
    "            if year is not None:\n",
    "                pub_date = year.text\n",
    "                if month is not None:\n",
    "                    pub_date += '-' + month.text\n",
    "                    if day is not None:\n",
    "                        pub_date += '-' + day.text\n",
    "    if pub_date is np.NaN:\n",
    "        pub_date = parse_pub_date(subroot, 'ppub')\n",
    "    return pub_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:37:24.602678Z",
     "start_time": "2020-08-02T21:37:24.586658Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_authors(subroot, path):\n",
    "    \"\"\"Returns parsed authors string from given ET <subroot>\"\"\"\n",
    "    authors = []\n",
    "    contributors = subroot.findall(path)\n",
    "    for contributor in contributors:\n",
    "        for contributor_meta in contributor.iter('name'):\n",
    "            surname = contributor_meta.find('surname')\n",
    "            given_name = contributor_meta.find('given-names')\n",
    "            if (surname is not None) and (given_name is not None):\n",
    "                surname = surname.text if surname.text is not None else ''\n",
    "                given_name = given_name.text if given_name.text is not None else ''\n",
    "                authors.append(' '.join([given_name, surname]))\n",
    "    if len(authors) > 0:\n",
    "        authors = ', '.join(authors)\n",
    "        authors = ' '.join(authors.split())\n",
    "    if authors:\n",
    "        return authors\n",
    "    return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:37:24.618669Z",
     "start_time": "2020-08-02T21:37:24.602678Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_keywords(subroot):\n",
    "    \"\"\"Returns parsed keywords string from given ET <subroot>\"\"\"\n",
    "    keywords = []\n",
    "    kwds = subroot.find('kwd-group')\n",
    "    if kwds is not None:\n",
    "        for kwd in kwds.iter('kwd'):\n",
    "            if kwd is not None and kwd.text is not None:\n",
    "                keywords.append(kwd.text)\n",
    "    if len(keywords) > 0:\n",
    "        keywords = '; '.join(keywords)\n",
    "        return keywords\n",
    "    return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:37:24.634628Z",
     "start_time": "2020-08-02T21:37:24.618669Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_issue(subroot):\n",
    "    \"\"\"Returns parsed journal issue dict from given ET <subroot>\"\"\"\n",
    "    journal_issue = {}\n",
    "    volume = subroot.find('volume')                            # Volume\n",
    "    if volume is not None:\n",
    "        journal_issue['volume'] = volume.text\n",
    "        \n",
    "    elocation_id = subroot.find('elocation-id')                # Elocation-id\n",
    "    if elocation_id is not None:\n",
    "        journal_issue['elocation-id'] = elocation_id.text\n",
    "        \n",
    "    issue = subroot.find('issue')                              # Issue\n",
    "    if issue is not None:\n",
    "        journal_issue['issue'] = issue.text\n",
    "        \n",
    "    fpage = subroot.find('fpage')                              # Pages\n",
    "    fpage = fpage.text if fpage is not None else None\n",
    "    lpage = subroot.find('lpage')\n",
    "    lpage = lpage.text if lpage is not None else None\n",
    "    \n",
    "    if isinstance(fpage, str) and isinstance(lpage, str):\n",
    "        journal_issue['pages'] = '-'.join([fpage, lpage])\n",
    "        \n",
    "    return journal_issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:37:24.650617Z",
     "start_time": "2020-08-02T21:37:24.634628Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_journal_meta(subroot, path):\n",
    "    \"\"\"Returns parsed journal meta dict from given ET <subroot>\"\"\"\n",
    "    journal_meta = {}\n",
    "    meta = subroot.find(path)\n",
    "    if meta is not None:\n",
    "        journal_ids = meta.findall('journal-id')                                            # Journal ids\n",
    "        for journal_id in journal_ids:\n",
    "            journal_meta['journal-id_' + journal_id.attrib.get('journal-id-type')] = journal_id.text\n",
    "            \n",
    "        issns = meta.findall('issn')                                                        # ISSNs\n",
    "        for issn in issns:\n",
    "            journal_meta['issn_' + issn.attrib.get('pub-type')] = issn.text\n",
    "        \n",
    "        journal_title = meta.find('journal-title-group/journal-title')                      # Journal title\n",
    "        if (journal_title is not None) and (journal_title.text is not None):\n",
    "            journal_meta['journal_title'] = journal_title.text\n",
    "            \n",
    "        publisher = meta.find('publisher')                                                  # Publisher\n",
    "        if publisher is not None:\n",
    "            publisher_name = publisher.find('publisher-name')                               # Publisher's name\n",
    "            if (publisher_name is not None) and (publisher_name.text is not None):\n",
    "                journal_meta['publisher_name'] = publisher_name.text\n",
    "                \n",
    "            publisher_loc = publisher.find('publisher-loc')                                 # Publisher's location\n",
    "            if (publisher_loc is not None) and (publisher_loc.text is not None):\n",
    "                journal_meta['publisher_loc'] = publisher_loc.text\n",
    "    return journal_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:37:24.666640Z",
     "start_time": "2020-08-02T21:37:24.650617Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_text(subroot, path):\n",
    "    \"\"\"Returns extracted text between xml tags\"\"\"\n",
    "    text = ''\n",
    "    if path == '':\n",
    "        section = subroot\n",
    "    else:\n",
    "        section = subroot.find(path)\n",
    "    if section is not None:\n",
    "        for element in section.iter():\n",
    "            if element.text:\n",
    "                text = text + element.text + ' '\n",
    "            if element.tail:\n",
    "                text = text + element.tail + ' '\n",
    "        text = ' '.join(text.split())\n",
    "    if text:\n",
    "        return text\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:37:24.762542Z",
     "start_time": "2020-08-02T21:37:24.746552Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_element_tree_pmc(root):\n",
    "    \"\"\"Returns parsed dict with all values found\"\"\"\n",
    "    item = {}\n",
    "    \n",
    "    item['article-type'] = root.find('article').get('article-type')                             # Article type\n",
    "    article_meta = root.findall('article/front/article-meta')                                   # Article meta\n",
    "    for meta in article_meta:\n",
    "        article_ids = meta.findall('article-id')                                                # Article ids\n",
    "        for article_id in article_ids:\n",
    "            item[article_id.get('pub-id-type')] = article_id.text\n",
    "            \n",
    "        category = meta.find('article-categories/subj-group/subject')                           # Article category\n",
    "        if category is not None:\n",
    "            item['category'] = category.text\n",
    "            \n",
    "        item['title'] = extract_text(meta, 'title-group/article-title')                         # Article title\n",
    "        item['authors'] = parse_authors(meta, 'contrib-group/contrib')                          # Authors\n",
    "        item['pub_date'] = parse_pub_date(meta, 'epub')                                         # Publication date\n",
    "    \n",
    "        copyright = meta.find('permissions/copyright-statement')                                # Copyright statement\n",
    "        if copyright is not None:\n",
    "            item['copyright'] = copyright.text\n",
    "        license_type = meta.find('permissions/license')                                         # License type\n",
    "        if license_type is not None:\n",
    "            item['license-type'] = license_type.get('license-type')\n",
    "        item['license'] = extract_text(meta, 'permissions/license/license-p')                   # License text\n",
    "        \n",
    "        item['keywords'] = parse_keywords(meta)                                                 # Keywords\n",
    "        item['abstract'] = extract_text(meta, 'abstract')                                       # Abstract\n",
    "        item.update(parse_issue(meta))                                                          # Journal issue\n",
    "    \n",
    "    item.update(parse_journal_meta(root, 'article/front/journal-meta'))                         # Journal meta\n",
    "    item['full_text'] = extract_text(root, 'article/body')\n",
    "    item['abstract_len'] = len(item['abstract']) if item['abstract'] is not np.NaN else 0\n",
    "    item['full_text_len'] = len(item['full_text']) if item['full_text'] is not np.NaN else 0\n",
    "            \n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:37:24.917527Z",
     "start_time": "2020-08-02T21:37:24.901667Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_top_level_subroots_pubmed(root):\n",
    "    \"\"\"Return top-level subroots and item dict with an article-type from given ET <root>\"\"\"\n",
    "    item = {}\n",
    "    article_type = 'pubmed_article'\n",
    "    \n",
    "    pubmed_data = root.find('PubmedArticle/PubmedData')                                         # Pubmed data subroot\n",
    "    if pubmed_data is None:\n",
    "        pubmed_data = root.find('PubmedBookArticle/PubmedBookData')\n",
    "        \n",
    "    article_meta = root.find('PubmedArticle/MedlineCitation/Article')                           # Article meta subroot\n",
    "    if article_meta is None:\n",
    "        article_meta = root.find('PubmedBookArticle/BookDocument')\n",
    "        if article_meta is not None:\n",
    "            article_type = 'book'\n",
    "        else:\n",
    "            article_type = 'unknown'\n",
    "            \n",
    "    item['article_type'] = article_type                                                         # Article type\n",
    "    \n",
    "    return item, pubmed_data, article_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:37:25.069427Z",
     "start_time": "2020-08-02T21:37:25.053442Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_ids_pubmed(subroot):\n",
    "    \"\"\"Returns parsed ids dict from given ET <subroot>\"\"\"\n",
    "    ids = {}\n",
    "    article_ids = subroot.findall('ArticleIdList/ArticleId')                                    # Article ids\n",
    "    if article_ids is not None:\n",
    "        for article_id in article_ids:\n",
    "            if article_id.get('IdType') == 'pubmed':\n",
    "                ids['pmid'] = article_id.text\n",
    "            else:\n",
    "                ids[article_id.get('IdType')] = article_id.text\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:37:25.237528Z",
     "start_time": "2020-08-02T21:37:25.221547Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_article_meta_pubmed(subroot):\n",
    "    \"\"\"Returns parsed dict with article meta from given ET <subroot>\"\"\"\n",
    "    article_meta_dict = {}\n",
    "    \n",
    "    title = subroot.find('ArticleTitle')                                                        # Title\n",
    "    if title is not None:\n",
    "        article_meta_dict['title'] = title.text\n",
    "    \n",
    "    pages = subroot.find('Pagination/MedlinePgn')                                               # Pagination\n",
    "    if pages is not None:\n",
    "        article_meta_dict['pages'] = pages.text\n",
    "    \n",
    "    elocation_id = subroot.find('ELocationID')                                                  # Elocation ID\n",
    "    if elocation_id is not None:\n",
    "        article_meta_dict['elocation_id'] = elocation_id.text\n",
    "        \n",
    "    language = subroot.find('Language')                                                         # Language\n",
    "    if language is not None:\n",
    "        article_meta_dict['language'] = language.text\n",
    "        \n",
    "    pub_types = subroot.findall('PublicationTypeList/PublicationType')                          # Publication types\n",
    "    if pub_types is not None:\n",
    "        pub_types_list = [pub_type.text for pub_type in pub_types if isinstance(pub_type.text, str)]\n",
    "        if pub_types_list:\n",
    "            article_meta_dict['publication_type'] = '; '.join(pub_types_list)\n",
    "    \n",
    "    return article_meta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:37:25.397430Z",
     "start_time": "2020-08-02T21:37:25.389435Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_authors_pubmed(subroot):\n",
    "    \"\"\"Returns parsed dict with authors found in given ET <subroot>\"\"\"\n",
    "    authors_dict = {}\n",
    "    authors_list = []\n",
    "    \n",
    "    authors = subroot.findall('AuthorList/Author')                                              # Authors\n",
    "    if authors is not None:\n",
    "        for author in authors:\n",
    "            fullname = ''\n",
    "            lastname = author.find('LastName')\n",
    "            if (lastname is not None) and (lastname.text is not None):\n",
    "                fullname += lastname.text\n",
    "                forename = author.find('ForeName')\n",
    "                if (forename is not None) and (forename.text is not None):\n",
    "                    fullname += ' ' + forename.text\n",
    "            if fullname:\n",
    "                authors_list.append(fullname)\n",
    "    if authors_list:\n",
    "        authors_dict['authors'] = '; '.join(authors_list)\n",
    "    \n",
    "    return authors_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:37:25.565295Z",
     "start_time": "2020-08-02T21:37:25.557327Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_abstract_pubmed(subroot):\n",
    "    \"\"\"Returns parsed abstract from given ET <subroot>\"\"\"\n",
    "    abstract_dict = {}\n",
    "    abstract = ''\n",
    "    abstract_meta = subroot.findall('Abstract/AbstractText')                                    # Abstract\n",
    "    if abstract_meta is not None:\n",
    "        if len(abstract_meta) > 1:\n",
    "            for i in range(len(abstract_meta)):\n",
    "                label = abstract_meta[i].get('Label', 'UNNAMED')\n",
    "                abstract = abstract + label + ': ' + extract_text(abstract_meta[i], '') + ' '\n",
    "        elif len(abstract_meta) == 1:\n",
    "            abstract = extract_text(abstract_meta[0], '')\n",
    "    abstract_dict['abstract'] = abstract\n",
    "    abstract_dict['abstract_len'] = len(abstract)                                               # Abstract length\n",
    "    \n",
    "    copyright = subroot.find('Abstract/CopyrightInformation')                                   # Copyright information\n",
    "    if (copyright is not None) and (copyright.text is not None):\n",
    "        abstract_dict['copyright'] = copyright.text\n",
    "    \n",
    "    return abstract_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:37:26.072665Z",
     "start_time": "2020-08-02T21:37:26.049598Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_jounal_meta_pubmed(subroot):\n",
    "    \"\"\"Returns parsed dict with journal meta from given ET <subroot>\"\"\"\n",
    "    journal_meta_dict = {}\n",
    "    \n",
    "    journal_meta = subroot.find('Journal')\n",
    "    if journal_meta is None:        \n",
    "        return journal_meta_dict\n",
    "    \n",
    "    issns = journal_meta.findall('ISSN')                                                        # ISSNs\n",
    "    if issns is not None:\n",
    "        for issn in issns:\n",
    "            journal_meta_dict['issn_' + issn.attrib.get('IssnType', '').lower()] = issn.text\n",
    "            \n",
    "    journal_title = journal_meta.find('Title')                                                  # Journal title\n",
    "    if (journal_title is not None) and (journal_title.text is not None):\n",
    "        journal_meta_dict['journal_title'] = journal_title.text\n",
    "        \n",
    "    journal_iso_abbr = journal_meta.find('ISOAbbreviation')                                     # Journal ISO abbreviation\n",
    "    if (journal_iso_abbr is not None) and (journal_iso_abbr.text is not None):\n",
    "        journal_meta_dict['journal_iso_abbr'] = journal_iso_abbr.text\n",
    "        \n",
    "    journal_issue = journal_meta.find('JournalIssue')                                           # Journal issue\n",
    "    if journal_issue is not None:\n",
    "        volume = journal_issue.find('Volume')                                                   # Journal volume\n",
    "        if (volume is not None) and (volume.text is not None):\n",
    "            journal_meta_dict['volume'] = volume.text\n",
    "            \n",
    "        issue = journal_issue.find('Issue')                                                     # Journal issue\n",
    "        if (issue is not None) and (issue.text is not None):\n",
    "            journal_meta_dict['issue'] = issue.text\n",
    "        \n",
    "        pub_date = journal_issue.find('PubDate')                                                # Journal pub date\n",
    "        if pub_date is not None:\n",
    "            medline_date = pub_date.find('MedlineDate')\n",
    "            if (medline_date is not None) and (medline_date.text is not None):  # Simple case\n",
    "                journal_meta_dict['pub_date'] = medline_date.text\n",
    "            else:                                                               # Complex case\n",
    "                year  = pub_date.find('Year')\n",
    "                month = pub_date.find('Month')\n",
    "                day   = pub_date.find('Day')\n",
    "                date  = ''  + year.text  if (year  is not None) and (year.text  is not None) else ''\n",
    "                date += '-' + month.text if (month is not None) and (month.text is not None) else ''\n",
    "                date += '-' + day.text   if (day   is not None) and (day.text   is not None) else ''\n",
    "                if date:\n",
    "                    journal_meta_dict['pub_date'] = date\n",
    "    \n",
    "    return journal_meta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:37:26.232591Z",
     "start_time": "2020-08-02T21:37:26.216697Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_publisher_pubmed(root):\n",
    "    \"\"\"Returnes parsed dict with publisher information from given ET <root>\"\"\"\n",
    "    publisher_dict = {}\n",
    "    \n",
    "    publisher = root.find('PubmedArticle/MedlineCitation/MedlineJournalInfo')\n",
    "    if publisher is not None:\n",
    "        name = publisher.find('MedlineTA')                                                     # Publisher name\n",
    "        if (name is not None) and (name.text is not None):\n",
    "            publisher_dict['publisher_name'] = name.text\n",
    "            \n",
    "        country = publisher.find('Country')                                                    # Publisher country\n",
    "        if (country is not None) and (country.text is not None):\n",
    "            publisher_dict['publisher_location'] = country.text\n",
    "            \n",
    "        nlm_id = publisher.find('NlmUniqueID')                                                 # Publisher NLM ID\n",
    "        if (nlm_id is not None) and (nlm_id.text is not None):\n",
    "            publisher_dict['publisher_nlm_id'] = nlm_id.text\n",
    "            \n",
    "        issn_linking = publisher.find('ISSNLinking')                                           # Publisher ISSN Linking\n",
    "        if (issn_linking is not None) and (issn_linking.text is not None):\n",
    "            publisher_dict['publisher_issn_linking'] = issn_linking.text\n",
    "    \n",
    "    return publisher_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:37:26.601575Z",
     "start_time": "2020-08-02T21:37:26.577558Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_mesh_terms_pubmed(root):\n",
    "    \"\"\"Returns parsed dict with all MeSH terms found in ET <root>\"\"\"\n",
    "    mesh_dict = {}\n",
    "    descriptors = quals_major = quals_minor = []\n",
    "    \n",
    "    meshes = root.findall('PubmedArticle/MedlineCitation/MeshHeadingList/MeshHeading')\n",
    "    if meshes is not None:\n",
    "        for mesh in meshes:\n",
    "            descriptor = mesh.find('DescriptorName')                                            # MeSH descriptors\n",
    "            if (descriptor is not None) and (descriptor.text is not None):\n",
    "                descriptors.append(descriptor.text)\n",
    "            \n",
    "            qualifiers = mesh.findall('QualifierName')                                          # MeSH qualifiers\n",
    "            if qualifiers is not None:\n",
    "                for qualifier in qualifiers:\n",
    "                    if qualifier.text is not None:\n",
    "                        if qualifier.attrib.get('MajorTopicYN', '') == 'Y':                     # MeSH major qualifiers\n",
    "                            quals_major.append(qualifier.text)\n",
    "                        elif qualifier.attrib.get('MajorTopicYN', '') == 'N':                   # MeSH minor qualifiers\n",
    "                            quals_minor.append(qualifier.text)\n",
    "    if descriptors:\n",
    "        mesh_dict['mesh_descriptors'] = '; '.join(set(descriptors))\n",
    "    if quals_major:\n",
    "        mesh_dict['mesh_quals_major'] = '; '.join(set(quals_major))\n",
    "    if quals_minor:\n",
    "        mesh_dict['mesh_quals_minor'] = '; '.join(set(quals_minor))\n",
    "        \n",
    "    keywords = root.findall('PubmedArticle/MedlineCitation/KeywordList/Keyword')                # Keywords\n",
    "    if keywords is not None:\n",
    "        keywords_list = [keyword.text for keyword in keywords if keyword.text is not None]\n",
    "        if keywords_list:\n",
    "            mesh_dict['keywords'] = '; '.join(keywords_list)\n",
    "            \n",
    "    \n",
    "    return mesh_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:37:26.893246Z",
     "start_time": "2020-08-02T21:37:26.870395Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_element_tree_pubmed(root):\n",
    "    \"\"\"Returns parsed dict with all values found\"\"\"\n",
    "    item, pubmed_data, article_meta = parse_top_level_subroots_pubmed(root)                     # Top-level subroots\n",
    "    item.update(parse_ids_pubmed(pubmed_data))                                                  # Article ids\n",
    "    item.update(parse_article_meta_pubmed(article_meta))                                        # Article meta-information\n",
    "    item.update(parse_authors_pubmed(article_meta))                                             # Authors\n",
    "    item.update(parse_abstract_pubmed(article_meta))                                            # Abstract\n",
    "    item.update(parse_jounal_meta_pubmed(article_meta))                                         # Journal meta\n",
    "    item.update(parse_publisher_pubmed(root))                                                   # Publisher information\n",
    "    item.update(parse_mesh_terms_pubmed(root))                                                  # MeSH terms\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:37:27.214591Z",
     "start_time": "2020-08-02T21:37:27.206557Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_element_tree(filename):\n",
    "    \"\"\"Returns parsed ElementTree object of an article stored in <filename>\"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        return None\n",
    "    \n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()        \n",
    "    root = ET.fromstring(data)\n",
    "    \n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:40:13.112921Z",
     "start_time": "2020-08-02T21:40:13.086148Z"
    }
   },
   "outputs": [],
   "source": [
    "def handle_query_responses(db, article_ids):\n",
    "    \"\"\"Returns articles DataFrame\"\"\"\n",
    "    items_list = []\n",
    "    filenames = [os.path.join(db, str(article_id)) for article_id in article_ids]\n",
    "    print('{0} query responses found. Starting...'.format(len(filenames)))\n",
    "    time.sleep(1)\n",
    "    \n",
    "    if db == 'pmc':\n",
    "        items = pd.DataFrame(columns=['pmid', 'pmc', 'publisher-id', 'doi', 'abstract_len', 'full_text_len', 'file_size',\n",
    "                                      'title', 'article-type', 'category', 'authors', 'pub_date', 'keywords',\n",
    "                                      'volume', 'elocation-id', 'issue', 'pages', 'issn_epub', 'issn_ppub',\n",
    "                                      'journal-id_nlm-ta', 'journal_title', 'publisher_name', 'publisher_loc',\n",
    "                                      'copyright', 'license-type', 'license', 'abstract', 'full_text'])\n",
    "    elif db == 'pubmed':\n",
    "        items = pd.DataFrame(columns=['pmid', 'pmc', 'pii', 'mid', 'doi', 'elocation_id', 'language',\n",
    "                                      'title', 'authors', 'article_type', 'publication_type',\n",
    "                                      'journal_title', 'volume', 'issue', 'pages', 'pub_date',\n",
    "                                      'issn_electronic', 'issn_print', 'journal_iso_abbr',\n",
    "                                      'publisher_name', 'publisher_location', 'publisher_nlm_id', 'publisher_issn_linking',\n",
    "                                      'abstract_len', 'abstract', 'copyright',\n",
    "                                      'mesh_quals_major', 'mesh_quals_minor', 'mesh_descriptors', 'keywords', 'file_size'])\n",
    "    for i in range(0, len(filenames)):\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        #if filenames[i] in files_stoplist:\n",
    "        #    continue\n",
    "        print('Done {0} of {1}. Working on {2}'.format(i+1, len(filenames), filenames[i]))\n",
    "        \n",
    "        root = get_element_tree(filenames[i])\n",
    "        if db == 'pmc':\n",
    "            item = parse_element_tree_pmc(root)\n",
    "        elif db == 'pubmed':\n",
    "            item = parse_element_tree_pubmed(root)\n",
    "        item['file_size'] = os.path.getsize(filenames[i])\n",
    "        items_list.append(item)\n",
    "        #items = items.append(item, ignore_index=True)\n",
    "        if i % 5000 == 0:\n",
    "            items.to_csv('database/tmp.csv', sep='|', index=False)\n",
    "    \n",
    "    items = items.append(items_list)\n",
    "    clear_output(wait=True)\n",
    "    print('Work completed. Done {0} of {0}.'.format(len(filenames)))\n",
    "        \n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:37:28.038757Z",
     "start_time": "2020-08-02T21:37:28.022885Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_article_ids(query, db):\n",
    "    \"\"\"Returns all article ids found by <query>\"\"\"\n",
    "    article_ids = []\n",
    "    params = {\n",
    "        'db'       : db,\n",
    "        'api_key'  : api_key,\n",
    "        'term'     : query,\n",
    "        'retmax'   : max_results,\n",
    "        'retstart' : 0,\n",
    "        'retmode'  : retmode\n",
    "    }\n",
    "    count = params['retmax'] + 1\n",
    "    \n",
    "    while params['retstart'] < count:\n",
    "        try:\n",
    "            response = requests.get(url=url_search, headers=headers, params=params)\n",
    "        except requests.RequestException:\n",
    "            print('Problem has occured at retstart: {0}'.format(params['retstart']))\n",
    "        else:\n",
    "            root = ET.fromstring(response.text)\n",
    "            for article_id in root.iter('Id'):\n",
    "                article_ids.append(int(article_id.text))\n",
    "            count = int(root.find('Count').text)\n",
    "        finally:\n",
    "            params['retstart'] += params['retmax']\n",
    "\n",
    "    return article_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:37:28.430082Z",
     "start_time": "2020-08-02T21:37:28.406098Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_query_response(article_id, db, refresh=False):\n",
    "    \"\"\"Saves article query response with <article_id> identifier to file\"\"\"\n",
    "    params = {\n",
    "        'db'      : db,\n",
    "        'id'      : article_id,\n",
    "        'api_key' : api_key,\n",
    "        'retmode' : retmode\n",
    "    }\n",
    "    \n",
    "    filename = os.path.join(db, str(article_id))\n",
    "    if (os.path.exists(filename)) and (not refresh):\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "            response = requests.get(url=url_fetch, headers=headers, params=params)\n",
    "        except requests.RequestException:\n",
    "            print('Problem has occured with PMC ID: {0}'.format(article_id))\n",
    "        else:\n",
    "            data = response.text\n",
    "            with open(filename, 'w+', encoding='utf-8') as f:\n",
    "                f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:37:28.685878Z",
     "start_time": "2020-08-02T21:37:28.677912Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_all_query_responses(query, db, refresh=False):\n",
    "    \"\"\"Downloads all query responses got by <query>\"\"\"\n",
    "    article_ids = get_article_ids(query, db)\n",
    "    \n",
    "    article_ids = [str(article_id) for article_id in article_ids]\n",
    "    files_list = os.listdir(db)\n",
    "    intersection = list(set(article_ids) & set(files_list))\n",
    "    \n",
    "    print('{0} articles found in {1} with query specified.'.format(len(article_ids), db))\n",
    "    print('{0} articles are already stored in the database.'.format(len(intersection)))\n",
    "    print('{0} articles will be downloaded.'.format(len(article_ids) - len(intersection)))\n",
    "    \n",
    "    for article_id in article_ids:\n",
    "        download_query_response(article_id, db, refresh)\n",
    "    \n",
    "    files_count = len(os.listdir(db))\n",
    "    print('Total {0} articles stored in the database.'.format(files_count))\n",
    "    return article_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Neurosurgery articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:37:36.617529Z",
     "start_time": "2020-08-02T21:37:36.609533Z"
    }
   },
   "outputs": [],
   "source": [
    "db = 'pubmed'\n",
    "query = 'text classification neural network'\n",
    "query0 = 'neurosurgery'\n",
    "query1 = '(neurosurg*) AND (complicat*[Text Word])'\n",
    "query2 = '(\"Glioma/surgery\"[Mesh] OR \"Glioma/therapy\"[Mesh])'\n",
    "query3 = '(\"Neurosurgery\"[Mesh] OR \"Neurosurgical Procedures\"[Mesh]) AND \"Postoperative Complications\"[Mesh]'\n",
    "query4 = '(\"Neurosurgery\"[Mesh] OR \"Neurosurgical Procedures\"[Mesh]) AND complicat*[Text Word]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:37:41.136528Z",
     "start_time": "2020-08-02T21:37:39.426111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233 articles found in pubmed with query specified.\n",
      "232 articles are already stored in the database.\n",
      "1 articles will be downloaded.\n",
      "Total 238 articles stored in the database.\n"
     ]
    }
   ],
   "source": [
    "article_ids = download_all_query_responses(query=query, db=db, refresh=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle query responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:40:31.900684Z",
     "start_time": "2020-08-02T21:40:30.080332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work completed. Done 233 of 233.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>pmc</th>\n",
       "      <th>pii</th>\n",
       "      <th>mid</th>\n",
       "      <th>doi</th>\n",
       "      <th>elocation_id</th>\n",
       "      <th>language</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>article_type</th>\n",
       "      <th>...</th>\n",
       "      <th>publisher_nlm_id</th>\n",
       "      <th>publisher_issn_linking</th>\n",
       "      <th>abstract_len</th>\n",
       "      <th>abstract</th>\n",
       "      <th>copyright</th>\n",
       "      <th>mesh_quals_major</th>\n",
       "      <th>mesh_quals_minor</th>\n",
       "      <th>mesh_descriptors</th>\n",
       "      <th>keywords</th>\n",
       "      <th>file_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32729840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>v8i7e17784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.2196/17784</td>\n",
       "      <td>10.2196/17784</td>\n",
       "      <td>eng</td>\n",
       "      <td>Identifying and Predicting Intentional Self-Ha...</td>\n",
       "      <td>Obeid Jihad S; Dahne Jennifer; Christensen Sea...</td>\n",
       "      <td>pubmed_article</td>\n",
       "      <td>...</td>\n",
       "      <td>101645109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2309</td>\n",
       "      <td>BACKGROUND: Suicide is an important public hea...</td>\n",
       "      <td>©Jihad S Obeid, Jennifer Dahne, Sean Christens...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deep learning; electronic health records; mach...</td>\n",
       "      <td>11313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32673791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S1532-0464(20)30139-8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1016/j.jbi.2020.103511</td>\n",
       "      <td>S1532-0464(20)30139-8</td>\n",
       "      <td>eng</td>\n",
       "      <td>An Attention-based Multi-Task Model for Named ...</td>\n",
       "      <td>Wu Chaochen; Luo Guan; Guo Chao; Ren Yin; Zhen...</td>\n",
       "      <td>pubmed_article</td>\n",
       "      <td>...</td>\n",
       "      <td>100970413</td>\n",
       "      <td>1532-0464</td>\n",
       "      <td>794</td>\n",
       "      <td>In this paper, we propose an attention-based m...</td>\n",
       "      <td>Copyright © 2020. Published by Elsevier Inc.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deep learning; Intent analysis; Interpretabili...</td>\n",
       "      <td>7644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32590229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S1386-5056(19)31088-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1016/j.ijmedinf.2020.104225</td>\n",
       "      <td>S1386-5056(19)31088-3</td>\n",
       "      <td>eng</td>\n",
       "      <td>Clinical questionnaire filling based on questi...</td>\n",
       "      <td>Ren Jiangtao; Liu Naiyin; Wu Xiaojing</td>\n",
       "      <td>pubmed_article</td>\n",
       "      <td>...</td>\n",
       "      <td>9711057</td>\n",
       "      <td>1386-5056</td>\n",
       "      <td>1786</td>\n",
       "      <td>BACKGROUND: Electronic Health Records (EHR) ar...</td>\n",
       "      <td>Copyright © 2020 Elsevier B.V. All rights rese...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EHR; Information extraction; Medical text; Mul...</td>\n",
       "      <td>8217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32584774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1109/TNNLS.2020.3002798</td>\n",
       "      <td>10.1109/TNNLS.2020.3002798</td>\n",
       "      <td>eng</td>\n",
       "      <td>Automated Social Text Annotation With Joint Mu...</td>\n",
       "      <td>Dong Hang; Wang Wei; Huang Kaizhu; Coenen Frans</td>\n",
       "      <td>pubmed_article</td>\n",
       "      <td>...</td>\n",
       "      <td>101616214</td>\n",
       "      <td>2162-237X</td>\n",
       "      <td>1976</td>\n",
       "      <td>Automated social text annotation is the task o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32570656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SHTI200439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.3233/SHTI200439</td>\n",
       "      <td>10.3233/SHTI200439</td>\n",
       "      <td>eng</td>\n",
       "      <td>Predicting Diagnosis Code from Medication List...</td>\n",
       "      <td>Masud Jakir Hossain Bhuiyan; Lin Ming-Chin</td>\n",
       "      <td>pubmed_article</td>\n",
       "      <td>...</td>\n",
       "      <td>9214582</td>\n",
       "      <td>0926-9630</td>\n",
       "      <td>951</td>\n",
       "      <td>Automated coding and classification systems pl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clinical note; International Statistical Class...</td>\n",
       "      <td>5973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid  pmc                    pii  mid                             doi  \\\n",
       "0  32729840  NaN             v8i7e17784  NaN                   10.2196/17784   \n",
       "1  32673791  NaN  S1532-0464(20)30139-8  NaN       10.1016/j.jbi.2020.103511   \n",
       "2  32590229  NaN  S1386-5056(19)31088-3  NaN  10.1016/j.ijmedinf.2020.104225   \n",
       "3  32584774  NaN                    NaN  NaN      10.1109/TNNLS.2020.3002798   \n",
       "4  32570656  NaN             SHTI200439  NaN              10.3233/SHTI200439   \n",
       "\n",
       "                 elocation_id language  \\\n",
       "0               10.2196/17784      eng   \n",
       "1       S1532-0464(20)30139-8      eng   \n",
       "2       S1386-5056(19)31088-3      eng   \n",
       "3  10.1109/TNNLS.2020.3002798      eng   \n",
       "4          10.3233/SHTI200439      eng   \n",
       "\n",
       "                                               title  \\\n",
       "0  Identifying and Predicting Intentional Self-Ha...   \n",
       "1  An Attention-based Multi-Task Model for Named ...   \n",
       "2  Clinical questionnaire filling based on questi...   \n",
       "3  Automated Social Text Annotation With Joint Mu...   \n",
       "4  Predicting Diagnosis Code from Medication List...   \n",
       "\n",
       "                                             authors    article_type  ...  \\\n",
       "0  Obeid Jihad S; Dahne Jennifer; Christensen Sea...  pubmed_article  ...   \n",
       "1  Wu Chaochen; Luo Guan; Guo Chao; Ren Yin; Zhen...  pubmed_article  ...   \n",
       "2              Ren Jiangtao; Liu Naiyin; Wu Xiaojing  pubmed_article  ...   \n",
       "3    Dong Hang; Wang Wei; Huang Kaizhu; Coenen Frans  pubmed_article  ...   \n",
       "4         Masud Jakir Hossain Bhuiyan; Lin Ming-Chin  pubmed_article  ...   \n",
       "\n",
       "  publisher_nlm_id publisher_issn_linking abstract_len  \\\n",
       "0        101645109                    NaN         2309   \n",
       "1        100970413              1532-0464          794   \n",
       "2          9711057              1386-5056         1786   \n",
       "3        101616214              2162-237X         1976   \n",
       "4          9214582              0926-9630          951   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  BACKGROUND: Suicide is an important public hea...   \n",
       "1  In this paper, we propose an attention-based m...   \n",
       "2  BACKGROUND: Electronic Health Records (EHR) ar...   \n",
       "3  Automated social text annotation is the task o...   \n",
       "4  Automated coding and classification systems pl...   \n",
       "\n",
       "                                           copyright mesh_quals_major  \\\n",
       "0  ©Jihad S Obeid, Jennifer Dahne, Sean Christens...              NaN   \n",
       "1       Copyright © 2020. Published by Elsevier Inc.              NaN   \n",
       "2  Copyright © 2020 Elsevier B.V. All rights rese...              NaN   \n",
       "3                                                NaN              NaN   \n",
       "4                                                NaN              NaN   \n",
       "\n",
       "  mesh_quals_minor mesh_descriptors  \\\n",
       "0              NaN              NaN   \n",
       "1              NaN              NaN   \n",
       "2              NaN              NaN   \n",
       "3              NaN              NaN   \n",
       "4              NaN              NaN   \n",
       "\n",
       "                                            keywords file_size  \n",
       "0  deep learning; electronic health records; mach...     11313  \n",
       "1  Deep learning; Intent analysis; Interpretabili...      7644  \n",
       "2  EHR; Information extraction; Medical text; Mul...      8217  \n",
       "3                                                NaN      6098  \n",
       "4  Clinical note; International Statistical Class...      5973  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = handle_query_responses(db, article_ids)\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:41:25.150515Z",
     "start_time": "2020-08-02T21:41:25.123267Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 233 entries, 0 to 232\n",
      "Data columns (total 31 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   pmid                    233 non-null    object\n",
      " 1   pmc                     95 non-null     object\n",
      " 2   pii                     139 non-null    object\n",
      " 3   mid                     20 non-null     object\n",
      " 4   doi                     224 non-null    object\n",
      " 5   elocation_id            203 non-null    object\n",
      " 6   language                233 non-null    object\n",
      " 7   title                   233 non-null    object\n",
      " 8   authors                 233 non-null    object\n",
      " 9   article_type            233 non-null    object\n",
      " 10  publication_type        233 non-null    object\n",
      " 11  journal_title           233 non-null    object\n",
      " 12  volume                  222 non-null    object\n",
      " 13  issue                   147 non-null    object\n",
      " 14  pages                   215 non-null    object\n",
      " 15  pub_date                233 non-null    object\n",
      " 16  issn_electronic         189 non-null    object\n",
      " 17  issn_print              41 non-null     object\n",
      " 18  journal_iso_abbr        233 non-null    object\n",
      " 19  publisher_name          233 non-null    object\n",
      " 20  publisher_location      233 non-null    object\n",
      " 21  publisher_nlm_id        233 non-null    object\n",
      " 22  publisher_issn_linking  223 non-null    object\n",
      " 23  abstract_len            233 non-null    object\n",
      " 24  abstract                233 non-null    object\n",
      " 25  copyright               75 non-null     object\n",
      " 26  mesh_quals_major        157 non-null    object\n",
      " 27  mesh_quals_minor        157 non-null    object\n",
      " 28  mesh_descriptors        157 non-null    object\n",
      " 29  keywords                127 non-null    object\n",
      " 30  file_size               233 non-null    object\n",
      "dtypes: object(31)\n",
      "memory usage: 58.2+ KB\n"
     ]
    }
   ],
   "source": [
    "items.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:41:30.718328Z",
     "start_time": "2020-08-02T21:41:29.933751Z"
    }
   },
   "outputs": [],
   "source": [
    "items.to_csv('database/{0}_queryX.csv'.format(db), sep='|')\n",
    "items.to_excel('database/{0}_queryX.xlsx'.format(db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T12:48:42.730668Z",
     "start_time": "2020-07-30T12:48:42.719589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article_type': 'book',\n",
       " 'pmid': '32644742',\n",
       " 'title': 'Subacute Combined Degeneration of the Spinal Cord',\n",
       " 'language': 'eng',\n",
       " 'authors': 'Qudsiya Zainab; De Jesus Orlando',\n",
       " 'abstract': 'Subacute combined degeneration of the spinal cord is a neurological complication of vitamin B12 (cobalamin) deficiency. A deficiency of vitamin B12 can occur as a result of nutritional deficiency, reduced absorption due to altered gastrointestinal anatomy or function, or due to the intake of certain drugs. Subacute combined degeneration is characterized by degeneration of the dorsal columns and the lateral columns of the spinal cord due to demyelination. It commonly presents with sensory deficits, paresthesia, weakness, ataxia, and gait disturbance. In severe untreated cases, it can lead to spasticity and paraplegia. It is crucial to promptly identify and treat vitamin B12 deficiency to prevent the development of this serious neurological complication.',\n",
       " 'abstract_len': 762,\n",
       " 'copyright': 'Copyright © 2020, StatPearls Publishing LLC.'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'pubmed/32644742'\n",
    "root = get_element_tree(filename)\n",
    "item = {}\n",
    "parse_element_tree_pubmed(root)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
