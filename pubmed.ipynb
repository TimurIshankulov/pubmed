{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T10:13:19.780157Z",
     "start_time": "2020-07-29T10:13:19.380097Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T10:13:21.436092Z",
     "start_time": "2020-07-29T10:13:19.784149Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T10:13:21.451619Z",
     "start_time": "2020-07-29T10:13:21.438804Z"
    }
   },
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla / 5.0(Windows NT 10.0; Win64; x64) AppleWebKit / 537.36(KHTML, like Gecko) Chrome / 69.0.3497.81 Safari / 537.36'\n",
    "}\n",
    "\n",
    "api_key = '2839ed49187b099ec3d13cc079fc3ca0fc09'\n",
    "max_results = 5000\n",
    "retmode = 'xml'\n",
    "\n",
    "dbs = ['pmc', 'pubmed', 'database']\n",
    "for db in dbs:\n",
    "    if not os.path.exists(db):\n",
    "        os.makedirs(db)\n",
    "\n",
    "files_stoplist = ['6796246', '4669991', '4212306', '4070603', '4912513', '2799065', '5042924', '6032109', '5042923',\n",
    "                  '6555104', '5724662', '5493079', '6117636', '5933288', '6763540', '6493311', '6737605', '5637785']\n",
    "\n",
    "url_pubmed_to_pmc = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi'\n",
    "url_fetch = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi'\n",
    "url_search = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T10:13:21.467690Z",
     "start_time": "2020-07-29T10:13:21.454620Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_pub_date(subroot, pub_type):\n",
    "    \"\"\"Returns parsed publication date from given ET <subroot>\"\"\"\n",
    "    pub_date = np.NaN\n",
    "    pub_dates = subroot.findall('pub-date')\n",
    "    for pub_record in pub_dates:\n",
    "        if (pub_record.attrib.get('pub-type', '') == pub_type or\n",
    "            pub_record.attrib.get('date-type', '') == 'pub'):\n",
    "            day = pub_record.find('day')\n",
    "            month = pub_record.find('month')\n",
    "            year = pub_record.find('year')\n",
    "            if year is not None:\n",
    "                pub_date = year.text\n",
    "                if month is not None:\n",
    "                    pub_date += '-' + month.text\n",
    "                    if day is not None:\n",
    "                        pub_date += '-' + day.text\n",
    "    if pub_date is np.NaN:\n",
    "        pub_date = parse_pub_date(subroot, 'ppub')\n",
    "    return pub_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T10:13:21.484288Z",
     "start_time": "2020-07-29T10:13:21.471753Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_authors(subroot, path):\n",
    "    \"\"\"Returns parsed authors string from given ET <subroot>\"\"\"\n",
    "    authors = []\n",
    "    contributors = subroot.findall(path)\n",
    "    for contributor in contributors:\n",
    "        for contributor_meta in contributor.iter('name'):\n",
    "            surname = contributor_meta.find('surname')\n",
    "            given_name = contributor_meta.find('given-names')\n",
    "            if (surname is not None) and (given_name is not None):\n",
    "                surname = surname.text if surname.text is not None else ''\n",
    "                given_name = given_name.text if given_name.text is not None else ''\n",
    "                authors.append(' '.join([given_name, surname]))\n",
    "    if len(authors) > 0:\n",
    "        authors = ', '.join(authors)\n",
    "        authors = ' '.join(authors.split())\n",
    "    if authors:\n",
    "        return authors\n",
    "    return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T10:13:21.500663Z",
     "start_time": "2020-07-29T10:13:21.487636Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_keywords(subroot):\n",
    "    \"\"\"Returns parsed keywords string from given ET <subroot>\"\"\"\n",
    "    keywords = []\n",
    "    kwds = subroot.find('kwd-group')\n",
    "    if kwds is not None:\n",
    "        for kwd in kwds.iter('kwd'):\n",
    "            if kwd is not None and kwd.text is not None:\n",
    "                keywords.append(kwd.text)\n",
    "    if len(keywords) > 0:\n",
    "        keywords = '; '.join(keywords)\n",
    "        return keywords\n",
    "    return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T10:13:21.517655Z",
     "start_time": "2020-07-29T10:13:21.505184Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_issue(subroot):\n",
    "    \"\"\"Returns parsed journal issue dict from given ET <subroot>\"\"\"\n",
    "    journal_issue = {}\n",
    "    volume = subroot.find('volume')                            # Volume\n",
    "    if volume is not None:\n",
    "        journal_issue['volume'] = volume.text\n",
    "        \n",
    "    elocation_id = subroot.find('elocation-id')                # Elocation-id\n",
    "    if elocation_id is not None:\n",
    "        journal_issue['elocation-id'] = elocation_id.text\n",
    "        \n",
    "    issue = subroot.find('issue')                              # Issue\n",
    "    if issue is not None:\n",
    "        journal_issue['issue'] = issue.text\n",
    "        \n",
    "    fpage = subroot.find('fpage')                              # Pages\n",
    "    fpage = fpage.text if fpage is not None else None\n",
    "    lpage = subroot.find('lpage')\n",
    "    lpage = lpage.text if lpage is not None else None\n",
    "    \n",
    "    if isinstance(fpage, str) and isinstance(lpage, str):\n",
    "        journal_issue['pages'] = '-'.join([fpage, lpage])\n",
    "        \n",
    "    return journal_issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T10:13:21.602945Z",
     "start_time": "2020-07-29T10:13:21.586050Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_journal_meta(subroot, path):\n",
    "    \"\"\"Returns parsed journal meta dict from given ET <subroot>\"\"\"\n",
    "    journal_meta = {}\n",
    "    meta = subroot.find(path)\n",
    "    if meta is not None:\n",
    "        journal_ids = meta.findall('journal-id')                                            # Journal ids\n",
    "        for journal_id in journal_ids:\n",
    "            journal_meta['journal-id_' + journal_id.attrib.get('journal-id-type')] = journal_id.text\n",
    "            \n",
    "        issns = meta.findall('issn')                                                        # ISSNs\n",
    "        for issn in issns:\n",
    "            journal_meta['issn_' + issn.attrib.get('pub-type')] = issn.text\n",
    "        \n",
    "        journal_title = meta.find('journal-title-group/journal-title')                      # Journal title\n",
    "        if (journal_title is not None) and (journal_title.text is not None):\n",
    "            journal_meta['journal_title'] = journal_title.text\n",
    "            \n",
    "        publisher = meta.find('publisher')                                                  # Publisher\n",
    "        if publisher is not None:\n",
    "            publisher_name = publisher.find('publisher-name')                               # Publisher's name\n",
    "            if (publisher_name is not None) and (publisher_name.text is not None):\n",
    "                journal_meta['publisher_name'] = publisher_name.text\n",
    "                \n",
    "            publisher_loc = publisher.find('publisher-loc')                                 # Publisher's location\n",
    "            if (publisher_loc is not None) and (publisher_loc.text is not None):\n",
    "                journal_meta['publisher_loc'] = publisher_loc.text\n",
    "    return journal_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T10:13:21.782866Z",
     "start_time": "2020-07-29T10:13:21.771374Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_text(subroot, path):\n",
    "    \"\"\"Returns extracted text between xml tags\"\"\"\n",
    "    text = ''\n",
    "    if path == '':\n",
    "        section = subroot\n",
    "    else:\n",
    "        section = subroot.find(path)\n",
    "    if section is not None:\n",
    "        for element in section.iter():\n",
    "            if element.text:\n",
    "                text = text + element.text + ' '\n",
    "            if element.tail:\n",
    "                text = text + element.tail + ' '\n",
    "        text = ' '.join(text.split())\n",
    "    if text:\n",
    "        return text\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T10:13:21.989612Z",
     "start_time": "2020-07-29T10:13:21.968487Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_element_tree_pmc(root):\n",
    "    \"\"\"Returns parsed dict with all values found\"\"\"\n",
    "    item = {}\n",
    "    \n",
    "    item['article-type'] = root.find('article').get('article-type')                             # Article type\n",
    "    article_meta = root.findall('article/front/article-meta')                                   # Article meta\n",
    "    for meta in article_meta:\n",
    "        article_ids = meta.findall('article-id')                                                # Article ids\n",
    "        for article_id in article_ids:\n",
    "            item[article_id.get('pub-id-type')] = article_id.text\n",
    "            \n",
    "        category = meta.find('article-categories/subj-group/subject')                           # Article category\n",
    "        if category is not None:\n",
    "            item['category'] = category.text\n",
    "            \n",
    "        item['title'] = extract_text(meta, 'title-group/article-title')                         # Article title\n",
    "        item['authors'] = parse_authors(meta, 'contrib-group/contrib')                          # Authors\n",
    "        item['pub_date'] = parse_pub_date(meta, 'epub')                                         # Publication date\n",
    "    \n",
    "        copyright = meta.find('permissions/copyright-statement')                                # Copyright statement\n",
    "        if copyright is not None:\n",
    "            item['copyright'] = copyright.text\n",
    "        license_type = meta.find('permissions/license')                                         # License type\n",
    "        if license_type is not None:\n",
    "            item['license-type'] = license_type.get('license-type')\n",
    "        item['license'] = extract_text(meta, 'permissions/license/license-p')                   # License text\n",
    "        \n",
    "        item['keywords'] = parse_keywords(meta)                                                 # Keywords\n",
    "        item['abstract'] = extract_text(meta, 'abstract')                                       # Abstract\n",
    "        item.update(parse_issue(meta))                                                          # Journal issue\n",
    "    \n",
    "    item.update(parse_journal_meta(root, 'article/front/journal-meta'))                         # Journal meta\n",
    "    item['full_text'] = extract_text(root, 'article/body')\n",
    "    item['abstract_len'] = len(item['abstract']) if item['abstract'] is not np.NaN else 0\n",
    "    item['full_text_len'] = len(item['full_text']) if item['full_text'] is not np.NaN else 0\n",
    "            \n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T10:13:22.185045Z",
     "start_time": "2020-07-29T10:13:22.171305Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_top_level_subroots_pubmed(root):\n",
    "    \"\"\"Return top-level subroots and article-type from given ET <root>\"\"\"\n",
    "    article_type = 'pubmed_article'\n",
    "    pubmed_data = root.find('PubmedArticle/PubmedData')\n",
    "    if pubmed_data is None:\n",
    "        pubmed_data = root.find('PubmedBookArticle/PubmedBookData')\n",
    "    article_meta = root.find('PubmedArticle/MedlineCitation/Article')\n",
    "    if article_meta is None:\n",
    "        article_meta = root.find('PubmedBookArticle/BookDocument')\n",
    "        if article_meta is not None:\n",
    "            article_type = 'book'\n",
    "        else:\n",
    "            article_type = 'unknown'\n",
    "    return pubmed_data, article_meta, article_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T11:28:15.737912Z",
     "start_time": "2020-07-29T11:28:15.720429Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_article_meta_pubmed(subroot):\n",
    "    \"\"\"Returns parsed dict with article meta from given ET <subroot>\"\"\"\n",
    "    article_meta_dict = {}\n",
    "    \n",
    "    title = subroot.find('ArticleTitle')                                                   # Title\n",
    "    if title is not None:\n",
    "        article_meta_dict['title'] = title.text\n",
    "    \n",
    "    pages = subroot.find('Pagination/MedlinePgn')                                          # Pagination\n",
    "    if pages is not None:\n",
    "        article_meta_dict['pages'] = pages.text\n",
    "    \n",
    "    elocation_id = subroot.find('ELocationID')                                             # Elocation ID\n",
    "    if elocation_id is not None:\n",
    "        article_meta_dict['elocation_id'] = elocation_id.text\n",
    "        \n",
    "    language = subroot.find('Language')                                                    # Language\n",
    "    if language is not None:\n",
    "        article_meta_dict['language'] = language.text\n",
    "        \n",
    "    pub_types = subroot.findall('PublicationTypeList/PublicationType')                     # Publication types\n",
    "    if pub_types is not None:\n",
    "        pub_types_list = [pub_type.text for pub_type in pub_types if isinstance(pub_type.text, str)]\n",
    "        article_meta_dict['publication_type'] = '; '.join(pub_types_list)\n",
    "    \n",
    "    return article_meta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T10:13:22.579601Z",
     "start_time": "2020-07-29T10:13:22.570448Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_ids_pubmed(subroot, path):\n",
    "    \"\"\"Returns parsed ids dict from given ET <subroot>\"\"\"\n",
    "    ids = {}\n",
    "    article_ids = subroot.findall(path)\n",
    "    if article_ids is not None:\n",
    "        for article_id in article_ids:\n",
    "            if article_id.get('IdType') == 'pubmed':\n",
    "                ids['pmid'] = article_id.text\n",
    "            else:\n",
    "                ids[article_id.get('IdType')] = article_id.text\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T10:13:22.811616Z",
     "start_time": "2020-07-29T10:13:22.796470Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_abstract_pubmed(subroot, path):\n",
    "    \"\"\"Returns parsed abstract from given ET <subroot>\"\"\"\n",
    "    abstract = ''\n",
    "    abstract_meta = subroot.findall(path)\n",
    "    if abstract_meta is not None:\n",
    "        if len(abstract_meta) > 1:\n",
    "            for i in range(len(abstract_meta)):\n",
    "                label = abstract_meta[i].get('Label', 'UNNAMED')\n",
    "                abstract = abstract + label + ': ' + extract_text(abstract_meta[i], '') + ' '\n",
    "        elif len(abstract_meta) == 1:\n",
    "            abstract = extract_text(abstract_meta[0], '')\n",
    "    return abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T10:13:23.021960Z",
     "start_time": "2020-07-29T10:13:22.996312Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_jounal_meta_pubmed(subroot, path):\n",
    "    \"\"\"Returns parsed dict with journal meta from given ET <subroot>\"\"\"\n",
    "    journal_meta_dict = {}\n",
    "    \n",
    "    journal_meta = subroot.find(path)\n",
    "    if journal_meta is None:        \n",
    "        return journal_meta_dict\n",
    "    \n",
    "    issns = journal_meta.findall('ISSN')                                                        # ISSNs\n",
    "    if issns is not None:\n",
    "        for issn in issns:\n",
    "            journal_meta_dict['issn_' + issn.attrib.get('IssnType', '').lower()] = issn.text\n",
    "            \n",
    "    journal_title = journal_meta.find('Title')                                                  # Journal title\n",
    "    if (journal_title is not None) and (journal_title.text is not None):\n",
    "        journal_meta_dict['journal_title'] = journal_title.text\n",
    "        \n",
    "    journal_iso_abbr = journal_meta.find('ISOAbbreviation')                                     # Journal ISO abbreviation\n",
    "    if (journal_iso_abbr is not None) and (journal_iso_abbr.text is not None):\n",
    "        journal_meta_dict['journal_iso_abbr'] = journal_iso_abbr.text\n",
    "        \n",
    "    journal_issue = journal_meta.find('JournalIssue')                                           # Journal issue\n",
    "    if journal_issue is not None:\n",
    "        volume = journal_issue.find('Volume')                                                   # Journal volume\n",
    "        if (volume is not None) and (volume.text is not None):\n",
    "            journal_meta_dict['volume'] = volume.text\n",
    "            \n",
    "        issue = journal_issue.find('Issue')                                                     # Journal issue\n",
    "        if (issue is not None) and (issue.text is not None):\n",
    "            journal_meta_dict['issue'] = issue.text\n",
    "        \n",
    "        pub_date = journal_issue.find('PubDate')                                                # Journal pub date\n",
    "        if pub_date is not None:\n",
    "            medline_date = pub_date.find('MedlineDate')\n",
    "            if (medline_date is not None) and (medline_date.text is not None):  # Simple case\n",
    "                journal_meta_dict['pub_date'] = medline_date.text\n",
    "            else:                                                               # Complex case\n",
    "                year  = pub_date.find('Year')\n",
    "                month = pub_date.find('Month')\n",
    "                day   = pub_date.find('Day')\n",
    "                date  = ''\n",
    "                \n",
    "                date += ''  + year.text  if (year  is not None) and (year.text  is not None) else ''\n",
    "                date += '-' + month.text if (month is not None) and (month.text is not None) else ''\n",
    "                date += '-' + day.text   if (day   is not None) and (day.text   is not None) else ''\n",
    "                journal_meta_dict['pub_date'] = date if date != '' else np.NaN\n",
    "    \n",
    "    return journal_meta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T10:41:46.244477Z",
     "start_time": "2020-07-29T10:41:46.236560Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_element_tree_pubmed(root):\n",
    "    \"\"\"Returns parsed dict with all values found\"\"\"\n",
    "    item = {}\n",
    "    \n",
    "    pubmed_data, article_meta, article_type = parse_top_level_subroots_pubmed(root)             # Top-level subroots\n",
    "    item['article_type'] = article_type                                                         # Article type\n",
    "    if article_type == 'unknown':\n",
    "        return item\n",
    "    \n",
    "    item.update(parse_ids_pubmed(pubmed_data, 'ArticleIdList/ArticleId'))                       # Article ids\n",
    "    item.update(parse_article_meta_pubmed(article_meta))\n",
    "    item['abstract'] = parse_abstract_pubmed(article_meta, 'Abstract/AbstractText')             # Abstract\n",
    "    item['abstract_len'] = len(item['abstract'])                                                # Abstract length\n",
    "    \n",
    "    item.update(parse_jounal_meta_pubmed(article_meta, 'Journal'))\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T10:13:23.441018Z",
     "start_time": "2020-07-29T10:13:23.428559Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_element_tree(filename):\n",
    "    \"\"\"Returns parsed ElementTree object of an article stored in <filename>\"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        return None\n",
    "    \n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()        \n",
    "    root = ET.fromstring(data)\n",
    "    \n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T11:01:19.686143Z",
     "start_time": "2020-07-29T11:01:19.661445Z"
    }
   },
   "outputs": [],
   "source": [
    "def handle_query_responses(db, article_ids):\n",
    "    \"\"\"Returns articles DataFrame\"\"\"\n",
    "    filenames = [os.path.join(db, str(article_id)) for article_id in article_ids]\n",
    "    print('{0} query responses found. Starting...'.format(len(filenames)))\n",
    "    time.sleep(1)\n",
    "    \n",
    "    if db == 'pmc':\n",
    "        items = pd.DataFrame(columns=['pmid', 'pmc', 'publisher-id', 'doi', 'abstract_len', 'full_text_len', 'file_size',\n",
    "                                      'title', 'article-type', 'category', 'authors', 'pub_date', 'keywords',\n",
    "                                      'volume', 'elocation-id', 'issue', 'pages', 'issn_epub', 'issn_ppub',\n",
    "                                      'journal-id_nlm-ta', 'journal_title', 'publisher_name', 'publisher_loc',\n",
    "                                      'copyright', 'license-type', 'license', 'abstract', 'full_text'])\n",
    "    elif db == 'pubmed':\n",
    "        items = pd.DataFrame(columns=['pmid', 'pmc', 'pii', 'mid', 'doi', 'elocation_id', 'language',\n",
    "                                      'title', 'authors', 'article_type', 'publication_type',\n",
    "                                      'journal_title',\n",
    "                                      'volume', 'issue', 'pages', 'pub_date', 'issn_electronic', 'issn_print',\n",
    "                                      'journal_iso_abbr', 'publisher_name',\n",
    "                                      'publisher_loc',\n",
    "                                      'copyright', 'license-type', 'license',\n",
    "                                      'abstract_len', 'abstract', 'keywords', 'file_size'])\n",
    "    for i in range(0, len(filenames)):\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        #if filenames[i] in files_stoplist:\n",
    "        #    continue\n",
    "        print('Done {0} of {1}. Working on {2}'.format(i+1, len(filenames), filenames[i]))\n",
    "        \n",
    "        root = get_element_tree(filenames[i])\n",
    "        if db == 'pmc':\n",
    "            item = parse_element_tree_pmc(root)\n",
    "        elif db == 'pubmed':\n",
    "            item = parse_element_tree_pubmed(root)\n",
    "        item['file_size'] = os.path.getsize(filenames[i])\n",
    "        items = items.append(item, ignore_index=True)\n",
    "        if i % 5000 == 0:\n",
    "            items.to_csv('database/pmc.csv', sep='|', index=False)\n",
    "        \n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T10:13:24.844440Z",
     "start_time": "2020-07-29T10:13:24.831066Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_article_ids(query, db):\n",
    "    \"\"\"Returns all article ids found by <query>\"\"\"\n",
    "    params = {\n",
    "        'db': db,\n",
    "        'api_key': api_key,\n",
    "        'term': query,\n",
    "        'retmax': max_results,\n",
    "        'retstart': 0,\n",
    "        'retmode': retmode\n",
    "    }\n",
    "    article_ids = []\n",
    "    count = params['retmax'] + 1\n",
    "    \n",
    "    while params['retstart'] < count:\n",
    "        try:\n",
    "            response = requests.get(url=url_search, headers=headers, params=params)\n",
    "        except requests.RequestException:\n",
    "            print('Problem has occured at retstart: {0}'.format(params['retstart']))\n",
    "        else:\n",
    "            root = ET.fromstring(response.text)\n",
    "            for article_id in root.iter('Id'):\n",
    "                article_ids.append(int(article_id.text))\n",
    "            count = int(root.find('Count').text)\n",
    "        finally:\n",
    "            params['retstart'] += params['retmax']\n",
    "\n",
    "    return article_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T10:13:25.275540Z",
     "start_time": "2020-07-29T10:13:25.263901Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_query_response(article_id, db, refresh=False):\n",
    "    \"\"\"Saves article query response with <article_id> identifier to file\"\"\"\n",
    "    params = {\n",
    "        'db': db,\n",
    "        'id': article_id,\n",
    "        'api_key': api_key,\n",
    "        'retmode': retmode\n",
    "    }\n",
    "    \n",
    "    filename = os.path.join(db, str(article_id))\n",
    "    if (os.path.exists(filename)) and (not refresh):\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "            response = requests.get(url=url_fetch, headers=headers, params=params)\n",
    "        except requests.RequestException:\n",
    "            print('Problem has occured with PMC ID: {0}'.format(article_id))\n",
    "        else:\n",
    "            data = response.text\n",
    "            with open(filename, 'w+', encoding='utf-8') as f:\n",
    "                f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T10:13:26.231308Z",
     "start_time": "2020-07-29T10:13:26.218577Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_all_query_responses(query, db, refresh=False):\n",
    "    \"\"\"Downloads all query responses got by <query>\"\"\"\n",
    "    article_ids = get_article_ids(query, db)\n",
    "    \n",
    "    article_ids = [str(article_id) for article_id in article_ids]\n",
    "    files_list = os.listdir(db)\n",
    "    intersection = list(set(article_ids) & set(files_list))\n",
    "    \n",
    "    print('{0} articles found in {1} with query specified.'.format(len(article_ids), db))\n",
    "    print('{0} articles are already stored in the database.'.format(len(intersection)))\n",
    "    print('{0} articles will be downloaded.'.format(len(article_ids) - len(intersection)))\n",
    "    \n",
    "    for article_id in article_ids:\n",
    "        download_query_response(article_id, db, refresh)\n",
    "    \n",
    "    files_count = len(os.listdir(db))\n",
    "    print('Total {0} articles stored in the database.'.format(files_count))\n",
    "    return article_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Neurosurgery articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T10:42:28.679915Z",
     "start_time": "2020-07-29T10:42:28.665484Z"
    }
   },
   "outputs": [],
   "source": [
    "db = 'pubmed'\n",
    "query = 'text classification neural network'\n",
    "query1 = '(neurosurg*) AND (complicat*[Text Word])'\n",
    "query2 = '(\"Glioma/surgery\"[Mesh] OR \"Glioma/therapy\"[Mesh])'\n",
    "query3 = '(\"Neurosurgery\"[Mesh] OR \"Neurosurgical Procedures\"[Mesh]) AND \"Postoperative Complications\"[Mesh]'\n",
    "query4 = '(\"Neurosurgery\"[Mesh] OR \"Neurosurgical Procedures\"[Mesh]) AND complicat*[Text Word]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T10:42:30.121038Z",
     "start_time": "2020-07-29T10:42:28.876288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232 articles found in pubmed with query specified.\n",
      "232 articles are already stored in the database.\n",
      "0 articles will be downloaded.\n",
      "Total 235 articles stored in the database.\n"
     ]
    }
   ],
   "source": [
    "article_ids = download_all_query_responses(query=query, db=db, refresh=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle query responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T11:26:14.843230Z",
     "start_time": "2020-07-29T11:26:06.693622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 232 of 232. Working on pubmed\\7949911\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>pmc</th>\n",
       "      <th>pii</th>\n",
       "      <th>mid</th>\n",
       "      <th>doi</th>\n",
       "      <th>elocation_id</th>\n",
       "      <th>language</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>article_type</th>\n",
       "      <th>...</th>\n",
       "      <th>journal_iso_abbr</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>publisher_loc</th>\n",
       "      <th>copyright</th>\n",
       "      <th>license-type</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract_len</th>\n",
       "      <th>abstract</th>\n",
       "      <th>keywords</th>\n",
       "      <th>file_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32673791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S1532-0464(20)30139-8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1016/j.jbi.2020.103511</td>\n",
       "      <td>S1532-0464(20)30139-8</td>\n",
       "      <td>eng</td>\n",
       "      <td>An Attention-based Multi-Task Model for Named ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pubmed_article</td>\n",
       "      <td>...</td>\n",
       "      <td>J Biomed Inform</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>794</td>\n",
       "      <td>In this paper, we propose an attention-based m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32590229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S1386-5056(19)31088-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1016/j.ijmedinf.2020.104225</td>\n",
       "      <td>S1386-5056(19)31088-3</td>\n",
       "      <td>eng</td>\n",
       "      <td>Clinical questionnaire filling based on questi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pubmed_article</td>\n",
       "      <td>...</td>\n",
       "      <td>Int J Med Inform</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1786</td>\n",
       "      <td>BACKGROUND: Electronic Health Records (EHR) ar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32584774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1109/TNNLS.2020.3002798</td>\n",
       "      <td>10.1109/TNNLS.2020.3002798</td>\n",
       "      <td>eng</td>\n",
       "      <td>Automated Social Text Annotation With Joint Mu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pubmed_article</td>\n",
       "      <td>...</td>\n",
       "      <td>IEEE Trans Neural Netw Learn Syst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976</td>\n",
       "      <td>Automated social text annotation is the task o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32570656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SHTI200439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.3233/SHTI200439</td>\n",
       "      <td>10.3233/SHTI200439</td>\n",
       "      <td>eng</td>\n",
       "      <td>Predicting Diagnosis Code from Medication List...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pubmed_article</td>\n",
       "      <td>...</td>\n",
       "      <td>Stud Health Technol Inform</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>951</td>\n",
       "      <td>Automated coding and classification systems pl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32558750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1097/MAO.0000000000002710</td>\n",
       "      <td>10.1097/MAO.0000000000002710</td>\n",
       "      <td>eng</td>\n",
       "      <td>Predicting Postoperative Cochlear Implant Perf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pubmed_article</td>\n",
       "      <td>...</td>\n",
       "      <td>Otol. Neurotol.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2139</td>\n",
       "      <td>OBJECTIVES: To predict postoperative cochlear ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid  pmc                    pii  mid                             doi  \\\n",
       "0  32673791  NaN  S1532-0464(20)30139-8  NaN       10.1016/j.jbi.2020.103511   \n",
       "1  32590229  NaN  S1386-5056(19)31088-3  NaN  10.1016/j.ijmedinf.2020.104225   \n",
       "2  32584774  NaN                    NaN  NaN      10.1109/TNNLS.2020.3002798   \n",
       "3  32570656  NaN             SHTI200439  NaN              10.3233/SHTI200439   \n",
       "4  32558750  NaN                    NaN  NaN    10.1097/MAO.0000000000002710   \n",
       "\n",
       "                   elocation_id language  \\\n",
       "0         S1532-0464(20)30139-8      eng   \n",
       "1         S1386-5056(19)31088-3      eng   \n",
       "2    10.1109/TNNLS.2020.3002798      eng   \n",
       "3            10.3233/SHTI200439      eng   \n",
       "4  10.1097/MAO.0000000000002710      eng   \n",
       "\n",
       "                                               title authors    article_type  \\\n",
       "0  An Attention-based Multi-Task Model for Named ...     NaN  pubmed_article   \n",
       "1  Clinical questionnaire filling based on questi...     NaN  pubmed_article   \n",
       "2  Automated Social Text Annotation With Joint Mu...     NaN  pubmed_article   \n",
       "3  Predicting Diagnosis Code from Medication List...     NaN  pubmed_article   \n",
       "4  Predicting Postoperative Cochlear Implant Perf...     NaN  pubmed_article   \n",
       "\n",
       "   ...                   journal_iso_abbr publisher_name publisher_loc  \\\n",
       "0  ...                    J Biomed Inform            NaN           NaN   \n",
       "1  ...                   Int J Med Inform            NaN           NaN   \n",
       "2  ...  IEEE Trans Neural Netw Learn Syst            NaN           NaN   \n",
       "3  ...         Stud Health Technol Inform            NaN           NaN   \n",
       "4  ...                    Otol. Neurotol.            NaN           NaN   \n",
       "\n",
       "  copyright license-type license abstract_len  \\\n",
       "0       NaN          NaN     NaN          794   \n",
       "1       NaN          NaN     NaN         1786   \n",
       "2       NaN          NaN     NaN         1976   \n",
       "3       NaN          NaN     NaN          951   \n",
       "4       NaN          NaN     NaN         2139   \n",
       "\n",
       "                                            abstract keywords file_size  \n",
       "0  In this paper, we propose an attention-based m...      NaN      7644  \n",
       "1  BACKGROUND: Electronic Health Records (EHR) ar...      NaN      8217  \n",
       "2  Automated social text annotation is the task o...      NaN      6098  \n",
       "3  Automated coding and classification systems pl...      NaN      5973  \n",
       "4  OBJECTIVES: To predict postoperative cochlear ...      NaN     10105  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = handle_query_responses(db, article_ids)\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T11:26:18.351564Z",
     "start_time": "2020-07-29T11:26:18.329494Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 232 entries, 0 to 231\n",
      "Data columns (total 28 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   pmid              232 non-null    object\n",
      " 1   pmc               95 non-null     object\n",
      " 2   pii               138 non-null    object\n",
      " 3   mid               20 non-null     object\n",
      " 4   doi               223 non-null    object\n",
      " 5   elocation_id      202 non-null    object\n",
      " 6   language          232 non-null    object\n",
      " 7   title             232 non-null    object\n",
      " 8   authors           0 non-null      object\n",
      " 9   article_type      232 non-null    object\n",
      " 10  publication_type  232 non-null    object\n",
      " 11  journal_title     232 non-null    object\n",
      " 12  volume            221 non-null    object\n",
      " 13  issue             146 non-null    object\n",
      " 14  pages             214 non-null    object\n",
      " 15  pub_date          232 non-null    object\n",
      " 16  issn_electronic   189 non-null    object\n",
      " 17  issn_print        40 non-null     object\n",
      " 18  journal_iso_abbr  232 non-null    object\n",
      " 19  publisher_name    0 non-null      object\n",
      " 20  publisher_loc     0 non-null      object\n",
      " 21  copyright         0 non-null      object\n",
      " 22  license-type      0 non-null      object\n",
      " 23  license           0 non-null      object\n",
      " 24  abstract_len      232 non-null    object\n",
      " 25  abstract          232 non-null    object\n",
      " 26  keywords          0 non-null      object\n",
      " 27  file_size         232 non-null    object\n",
      "dtypes: object(28)\n",
      "memory usage: 50.9+ KB\n"
     ]
    }
   ],
   "source": [
    "items.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:43:58.566796Z",
     "start_time": "2019-12-03T05:43:30.917314Z"
    }
   },
   "outputs": [],
   "source": [
    "items.to_csv('database/pmc_all.csv', sep='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T09:43:47.650352Z",
     "start_time": "2020-07-18T09:43:47.639202Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article-type': 'book',\n",
       " 'pmid': '32644742',\n",
       " 'title': 'Subacute Combined Degeneration of the Spinal Cord',\n",
       " 'abstract_structured': False,\n",
       " 'abstract': 'Subacute combined degeneration of the spinal cord is a neurological complication of vitamin B12 (cobalamin) deficiency. A deficiency of vitamin B12 can occur as a result of nutritional deficiency, reduced absorption due to altered gastrointestinal anatomy or function, or due to the intake of certain drugs. Subacute combined degeneration is characterized by degeneration of the dorsal columns and the lateral columns of the spinal cord due to demyelination. It commonly presents with sensory deficits, paresthesia, weakness, ataxia, and gait disturbance. In severe untreated cases, it can lead to spasticity and paraplegia. It is crucial to promptly identify and treat vitamin B12 deficiency to prevent the development of this serious neurological complication.',\n",
       " 'abstract_len': 762}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'pubmed/32644742'\n",
    "root = get_element_tree(filename)\n",
    "item = {}\n",
    "parse_element_tree_pubmed(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T07:46:56.572215Z",
     "start_time": "2020-07-16T07:46:56.565241Z"
    }
   },
   "outputs": [],
   "source": [
    "article_meta = root.find('PubmedArticle/MedlineCitation/Article')\n",
    "#root.find('PubmedArticle/MedlineCitation/Article/ArticleTitle').text\n",
    "pubmed_data = root.find('PubmedArticle/PubmedData')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
