{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T12:49:43.528533Z",
     "start_time": "2020-07-28T12:49:42.990783Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T12:49:45.035765Z",
     "start_time": "2020-07-28T12:49:43.533375Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T12:49:45.060325Z",
     "start_time": "2020-07-28T12:49:45.041116Z"
    }
   },
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla / 5.0(Windows NT 10.0; Win64; x64) AppleWebKit / 537.36(KHTML, like Gecko) Chrome / 69.0.3497.81 Safari / 537.36'\n",
    "}\n",
    "\n",
    "api_key = '2839ed49187b099ec3d13cc079fc3ca0fc09'\n",
    "max_results = 5000\n",
    "retmode = 'xml'\n",
    "\n",
    "dbs = ['pmc', 'pubmed', 'database']\n",
    "for db in dbs:\n",
    "    if not os.path.exists(db):\n",
    "        os.makedirs(db)\n",
    "\n",
    "files_stoplist = ['6796246', '4669991', '4212306', '4070603', '4912513', '2799065', '5042924', '6032109', '5042923',\n",
    "                  '6555104', '5724662', '5493079', '6117636', '5933288', '6763540', '6493311', '6737605', '5637785']\n",
    "\n",
    "url_pubmed_to_pmc = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi'\n",
    "url_fetch = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi'\n",
    "url_search = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T12:49:45.076204Z",
     "start_time": "2020-07-28T12:49:45.063642Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_pub_date(subroot, pub_type):\n",
    "    \"\"\"Returns parsed publication date from given ET <subroot>\"\"\"\n",
    "    pub_date = np.NaN\n",
    "    pub_dates = subroot.findall('pub-date')\n",
    "    for pub_record in pub_dates:\n",
    "        if (pub_record.attrib.get('pub-type', '') == pub_type or\n",
    "            pub_record.attrib.get('date-type', '') == 'pub'):\n",
    "            day = pub_record.find('day')\n",
    "            month = pub_record.find('month')\n",
    "            year = pub_record.find('year')\n",
    "            if year is not None:\n",
    "                pub_date = year.text\n",
    "                if month is not None:\n",
    "                    pub_date += '-' + month.text\n",
    "                    if day is not None:\n",
    "                        pub_date += '-' + day.text\n",
    "    if pub_date is np.NaN:\n",
    "        pub_date = parse_pub_date(subroot, 'ppub')\n",
    "    return pub_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T12:49:45.099516Z",
     "start_time": "2020-07-28T12:49:45.080672Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_authors(subroot, path):\n",
    "    \"\"\"Returns parsed authors string from given ET <subroot>\"\"\"\n",
    "    authors = []\n",
    "    contributors = subroot.findall(path)\n",
    "    for contributor in contributors:\n",
    "        for contributor_meta in contributor.iter('name'):\n",
    "            surname = contributor_meta.find('surname')\n",
    "            given_name = contributor_meta.find('given-names')\n",
    "            if (surname is not None) and (given_name is not None):\n",
    "                surname = surname.text if surname.text is not None else ''\n",
    "                given_name = given_name.text if given_name.text is not None else ''\n",
    "                authors.append(' '.join([given_name, surname]))\n",
    "    if len(authors) > 0:\n",
    "        authors = ', '.join(authors)\n",
    "        authors = ' '.join(authors.split())\n",
    "    if authors:\n",
    "        return authors\n",
    "    return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T12:49:45.119150Z",
     "start_time": "2020-07-28T12:49:45.100542Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_keywords(subroot):\n",
    "    \"\"\"Returns parsed keywords string from given ET <subroot>\"\"\"\n",
    "    keywords = []\n",
    "    kwds = subroot.find('kwd-group')\n",
    "    if kwds is not None:\n",
    "        for kwd in kwds.iter('kwd'):\n",
    "            if kwd is not None and kwd.text is not None:\n",
    "                keywords.append(kwd.text)\n",
    "    if len(keywords) > 0:\n",
    "        keywords = '; '.join(keywords)\n",
    "        return keywords\n",
    "    return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T12:49:45.142159Z",
     "start_time": "2020-07-28T12:49:45.121759Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_issue(subroot):\n",
    "    \"\"\"Returns parsed journal issue dict from given ET <subroot>\"\"\"\n",
    "    journal_issue = {}\n",
    "    volume = subroot.find('volume')                            # Volume\n",
    "    if volume is not None:\n",
    "        journal_issue['volume'] = volume.text\n",
    "        \n",
    "    elocation_id = subroot.find('elocation-id')                # Elocation-id\n",
    "    if elocation_id is not None:\n",
    "        journal_issue['elocation-id'] = elocation_id.text\n",
    "        \n",
    "    issue = subroot.find('issue')                              # Issue\n",
    "    if issue is not None:\n",
    "        journal_issue['issue'] = issue.text\n",
    "        \n",
    "    fpage = subroot.find('fpage')                              # Pages\n",
    "    fpage = fpage.text if fpage is not None else None\n",
    "    lpage = subroot.find('lpage')\n",
    "    lpage = lpage.text if lpage is not None else None\n",
    "    \n",
    "    if isinstance(fpage, str) and isinstance(lpage, str):\n",
    "        journal_issue['pages'] = '-'.join([fpage, lpage])\n",
    "        \n",
    "    return journal_issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T12:49:45.157821Z",
     "start_time": "2020-07-28T12:49:45.143189Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_journal_meta(subroot, path):\n",
    "    \"\"\"Returns parsed journal meta dict from given ET <subroot>\"\"\"\n",
    "    journal_meta = {}\n",
    "    meta = subroot.find(path)\n",
    "    if meta is not None:\n",
    "        journal_ids = meta.findall('journal-id')                                            # Journal ids\n",
    "        for journal_id in journal_ids:\n",
    "            journal_meta['journal-id_' + journal_id.attrib.get('journal-id-type')] = journal_id.text\n",
    "            \n",
    "        issns = meta.findall('issn')                                                        # ISSNs\n",
    "        for issn in issns:\n",
    "            journal_meta['issn_' + issn.attrib.get('pub-type')] = issn.text\n",
    "        \n",
    "        journal_title = meta.find('journal-title-group/journal-title')                      # Journal title\n",
    "        if (journal_title is not None) and (journal_title.text is not None):\n",
    "            journal_meta['journal_title'] = journal_title.text\n",
    "            \n",
    "        publisher = meta.find('publisher')                                                  # Publisher\n",
    "        if publisher is not None:\n",
    "            publisher_name = publisher.find('publisher-name')                               # Publisher's name\n",
    "            if (publisher_name is not None) and (publisher_name.text is not None):\n",
    "                journal_meta['publisher_name'] = publisher_name.text\n",
    "                \n",
    "            publisher_loc = publisher.find('publisher-loc')                                 # Publisher's location\n",
    "            if (publisher_loc is not None) and (publisher_loc.text is not None):\n",
    "                journal_meta['publisher_loc'] = publisher_loc.text\n",
    "    return journal_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T12:49:45.173147Z",
     "start_time": "2020-07-28T12:49:45.159838Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_text(subroot, path):\n",
    "    \"\"\"Returns extracted text between xml tags\"\"\"\n",
    "    text = ''\n",
    "    if path == '':\n",
    "        section = subroot\n",
    "    else:\n",
    "        section = subroot.find(path)\n",
    "    if section is not None:\n",
    "        for element in section.iter():\n",
    "            if element.text:\n",
    "                text = text + element.text + ' '\n",
    "            if element.tail:\n",
    "                text = text + element.tail + ' '\n",
    "        text = ' '.join(text.split())\n",
    "    if text:\n",
    "        return text\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T12:49:45.276428Z",
     "start_time": "2020-07-28T12:49:45.255347Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_element_tree_pmc(root):\n",
    "    \"\"\"Returns parsed dict with all values found\"\"\"\n",
    "    item = {}\n",
    "    \n",
    "    item['article-type'] = root.find('article').get('article-type')                             # Article type\n",
    "    article_meta = root.findall('article/front/article-meta')                                   # Article meta\n",
    "    for meta in article_meta:\n",
    "        article_ids = meta.findall('article-id')                                                # Article ids\n",
    "        for article_id in article_ids:\n",
    "            item[article_id.get('pub-id-type')] = article_id.text\n",
    "            \n",
    "        category = meta.find('article-categories/subj-group/subject')                           # Article category\n",
    "        if category is not None:\n",
    "            item['category'] = category.text\n",
    "            \n",
    "        item['title'] = extract_text(meta, 'title-group/article-title')                         # Article title\n",
    "        item['authors'] = parse_authors(meta, 'contrib-group/contrib')                          # Authors\n",
    "        item['pub_date'] = parse_pub_date(meta, 'epub')                                         # Publication date\n",
    "    \n",
    "        copyright = meta.find('permissions/copyright-statement')                                # Copyright statement\n",
    "        if copyright is not None:\n",
    "            item['copyright'] = copyright.text\n",
    "        license_type = meta.find('permissions/license')                                         # License type\n",
    "        if license_type is not None:\n",
    "            item['license-type'] = license_type.get('license-type')\n",
    "        item['license'] = extract_text(meta, 'permissions/license/license-p')                   # License text\n",
    "        \n",
    "        item['keywords'] = parse_keywords(meta)                                                 # Keywords\n",
    "        item['abstract'] = extract_text(meta, 'abstract')                                       # Abstract\n",
    "        item.update(parse_issue(meta))                                                          # Journal issue\n",
    "    \n",
    "    item.update(parse_journal_meta(root, 'article/front/journal-meta'))                         # Journal meta\n",
    "    item['full_text'] = extract_text(root, 'article/body')\n",
    "    item['abstract_len'] = len(item['abstract']) if item['abstract'] is not np.NaN else 0\n",
    "    item['full_text_len'] = len(item['full_text']) if item['full_text'] is not np.NaN else 0\n",
    "            \n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T12:49:45.435151Z",
     "start_time": "2020-07-28T12:49:45.416584Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_top_level_subroots_pubmed(root):\n",
    "    \"\"\"Return top-level subroots and article-type from given ET <root>\"\"\"\n",
    "    article_type = 'pubmed_article'\n",
    "    pubmed_data = root.find('PubmedArticle/PubmedData')\n",
    "    if pubmed_data is None:\n",
    "        pubmed_data = root.find('PubmedBookArticle/PubmedBookData')\n",
    "    article_meta = root.find('PubmedArticle/MedlineCitation/Article')\n",
    "    if article_meta is None:\n",
    "        article_meta = root.find('PubmedBookArticle/BookDocument')\n",
    "        if article_meta is not None:\n",
    "            article_type = 'book'\n",
    "        else:\n",
    "            article_type = 'unknown'\n",
    "    return pubmed_data, article_meta, article_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T12:49:46.087137Z",
     "start_time": "2020-07-28T12:49:46.077114Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_ids_pubmed(subroot, path):\n",
    "    \"\"\"Returns parsed ids dict from given ET <subroot>\"\"\"\n",
    "    ids = {}\n",
    "    article_ids = subroot.findall(path)\n",
    "    if article_ids is not None:\n",
    "        for article_id in article_ids:\n",
    "            if article_id.get('IdType') == 'pubmed':\n",
    "                ids['pmid'] = article_id.text\n",
    "            else:\n",
    "                ids[article_id.get('IdType')] = article_id.text\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T12:49:45.613921Z",
     "start_time": "2020-07-28T12:49:45.600302Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_abstract_pubmed(subroot, path):\n",
    "    \"\"\"Returns parsed abstract from given ET <subroot>\"\"\"\n",
    "    abstract = ''\n",
    "    abstract_meta = subroot.findall(path)\n",
    "    if abstract_meta is not None:\n",
    "        if len(abstract_meta) > 1:\n",
    "            for i in range(len(abstract_meta)):\n",
    "                label = abstract_meta[i].get('Label', 'UNNAMED')\n",
    "                abstract = abstract + label + ': ' + extract_text(abstract_meta[i], '') + ' '\n",
    "        elif len(abstract_meta) == 1:\n",
    "            abstract = extract_text(abstract_meta[0], '')\n",
    "    return abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T14:05:02.460198Z",
     "start_time": "2020-07-28T14:05:02.435950Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_jounal_meta_pubmed(subroot, path):\n",
    "    \"\"\"Returns parsed dict with journal meta from given ET <subroot>\"\"\"\n",
    "    journal_meta_dict = {}\n",
    "    \n",
    "    journal_meta = subroot.find(path)\n",
    "    if journal_meta is None:        \n",
    "        return journal_meta_dict\n",
    "    \n",
    "    issns = journal_meta.findall('ISSN')                                                        # ISSNs\n",
    "    if issns is not None:\n",
    "        for issn in issns:\n",
    "            journal_meta_dict['issn_' + issn.attrib.get('IssnType', '').lower()] = issn.text\n",
    "            \n",
    "    journal_title = journal_meta.find('Title')                                                  # Journal title\n",
    "    if (journal_title is not None) and (journal_title.text is not None):\n",
    "        journal_meta_dict['journal_title'] = journal_title.text\n",
    "        \n",
    "    journal_iso_abbr = journal_meta.find('ISOAbbreviation')                                     # Journal ISO abbreviation\n",
    "    if (journal_iso_abbr is not None) and (journal_iso_abbr.text is not None):\n",
    "        journal_meta_dict['journal_iso_abbr'] = journal_iso_abbr.text\n",
    "        \n",
    "    journal_issue = journal_meta.find('JournalIssue')                                           # Journal issue\n",
    "    if journal_issue is not None:\n",
    "        volume = journal_issue.find('Volume')                                                   # Journal volume\n",
    "        if (volume is not None) and (volume.text is not None):\n",
    "            journal_meta_dict['volume'] = volume.text\n",
    "            \n",
    "        issue = journal_issue.find('Issue')                                                     # Journal issue\n",
    "        if (issue is not None) and (issue.text is not None):\n",
    "            journal_meta_dict['issue'] = issue.text\n",
    "        \n",
    "        pub_date = journal_issue.find('PubDate')                                                # Journal pub date\n",
    "        if pub_date is not None:\n",
    "            medline_date = pub_date.find('MedlineDate')\n",
    "            if (medline_date is not None) and (medline_date.text is not None):  # Simple case\n",
    "                journal_meta_dict['pub_date'] = medline_date.text\n",
    "            else:                                                               # Complex case\n",
    "                year  = pub_date.find('Year')\n",
    "                month = pub_date.find('Month')\n",
    "                day   = pub_date.find('Day')\n",
    "                date  = ''\n",
    "                \n",
    "                date += ''  + year.text  if (year  is not None) and (year.text  is not None) else ''\n",
    "                date += '-' + month.text if (month is not None) and (month.text is not None) else ''\n",
    "                date += '-' + day.text   if (day   is not None) and (day.text   is not None) else ''\n",
    "                journal_meta_dict['pub_date'] = date if date != '' else np.NaN\n",
    "    \n",
    "    return journal_meta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T13:19:23.248183Z",
     "start_time": "2020-07-28T13:19:23.231425Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_element_tree_pubmed(root):\n",
    "    \"\"\"Returns parsed dict with all values found\"\"\"\n",
    "    item = {}\n",
    "    \n",
    "    pubmed_data, article_meta, article_type = parse_top_level_subroots_pubmed(root)             # Top-level subroots\n",
    "    item['article-type'] = article_type                                                         # Article type\n",
    "    if article_type == 'unknown':\n",
    "        return item\n",
    "    \n",
    "    item.update(parse_ids_pubmed(pubmed_data, 'ArticleIdList/ArticleId'))                       # Article ids\n",
    "    title = article_meta.find('ArticleTitle')                                                   # Title\n",
    "    if title is not None:\n",
    "        item['title'] = title.text\n",
    "    item['abstract'] = parse_abstract_pubmed(article_meta, 'Abstract/AbstractText')             # Abstract\n",
    "    item['abstract_len'] = len(item['abstract'])                                                # Abstract length\n",
    "    \n",
    "    item.update(parse_jounal_meta_pubmed(article_meta, 'Journal'))\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T12:49:46.822405Z",
     "start_time": "2020-07-28T12:49:46.810561Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_element_tree(filename):\n",
    "    \"\"\"Returns parsed ElementTree object of an article stored in <filename>\"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        return None\n",
    "    \n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()        \n",
    "    root = ET.fromstring(data)\n",
    "    \n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T13:33:50.837751Z",
     "start_time": "2020-07-28T13:33:50.813180Z"
    }
   },
   "outputs": [],
   "source": [
    "def handle_query_responses(db, article_ids):\n",
    "    \"\"\"Returns articles DataFrame\"\"\"\n",
    "    filenames = [os.path.join(db, str(article_id)) for article_id in article_ids]\n",
    "    print('{0} query responses found. Starting...'.format(len(filenames)))\n",
    "    time.sleep(1)\n",
    "    \n",
    "    if db == 'pmc':\n",
    "        items = pd.DataFrame(columns=['pmid', 'pmc', 'publisher-id', 'doi', 'abstract_len', 'full_text_len', 'file_size',\n",
    "                                      'title', 'article-type', 'category', 'authors', 'pub_date', 'keywords',\n",
    "                                      'volume', 'elocation-id', 'issue', 'pages', 'issn_epub', 'issn_ppub',\n",
    "                                      'journal-id_nlm-ta', 'journal_title', 'publisher_name', 'publisher_loc',\n",
    "                                      'copyright', 'license-type', 'license', 'abstract', 'full_text'])\n",
    "    elif db == 'pubmed':\n",
    "        items = pd.DataFrame(columns=['pmid', 'pmc', 'pii', 'mid', 'publisher-id', 'doi', 'abstract_len', 'file_size',\n",
    "                                      'title', 'article-type', 'category', 'authors', 'pub_date', 'keywords',\n",
    "                                      'volume', 'elocation-id', 'issue', 'pages', 'issn_electronic', 'issn_print',\n",
    "                                      'journal-id_nlm-ta', 'journal_title', 'journal_iso_abbr', 'publisher_name',\n",
    "                                      'publisher_loc',\n",
    "                                      'copyright', 'license-type', 'license', 'abstract'])\n",
    "    for i in range(0, len(filenames)):\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        #if filenames[i] in files_stoplist:\n",
    "        #    continue\n",
    "        print('Done {0} of {1}. Working on {2}'.format(i+1, len(filenames), filenames[i]))\n",
    "        \n",
    "        root = get_element_tree(filenames[i])\n",
    "        if db == 'pmc':\n",
    "            item = parse_element_tree_pmc(root)\n",
    "        elif db == 'pubmed':\n",
    "            item = parse_element_tree_pubmed(root)\n",
    "        item['file_size'] = os.path.getsize(filenames[i])\n",
    "        items = items.append(item, ignore_index=True)\n",
    "        if i % 5000 == 0:\n",
    "            items.to_csv('database/pmc.csv', sep='|', index=False)\n",
    "        \n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T12:52:34.234152Z",
     "start_time": "2020-07-28T12:52:34.216808Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_article_ids(query, db):\n",
    "    \"\"\"Returns all article ids found by <query>\"\"\"\n",
    "    params = {\n",
    "        'db': db,\n",
    "        'api_key': api_key,\n",
    "        'term': query,\n",
    "        'retmax': max_results,\n",
    "        'retstart': 0,\n",
    "        'retmode': retmode\n",
    "    }\n",
    "    article_ids = []\n",
    "    count = params['retmax'] + 1\n",
    "    \n",
    "    while params['retstart'] < count:\n",
    "        try:\n",
    "            response = requests.get(url=url_search, headers=headers, params=params)\n",
    "        except requests.RequestException:\n",
    "            print('Problem has occured at retstart: {0}'.format(params['retstart']))\n",
    "        else:\n",
    "            root = ET.fromstring(response.text)\n",
    "            for article_id in root.iter('Id'):\n",
    "                article_ids.append(int(article_id.text))\n",
    "            count = int(root.find('Count').text)\n",
    "        finally:\n",
    "            params['retstart'] += params['retmax']\n",
    "\n",
    "    return article_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T12:52:34.382623Z",
     "start_time": "2020-07-28T12:52:34.363143Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_query_response(article_id, db, refresh=False):\n",
    "    \"\"\"Saves article query response with <article_id> identifier to file\"\"\"\n",
    "    params = {\n",
    "        'db': db,\n",
    "        'id': article_id,\n",
    "        'api_key': api_key,\n",
    "        'retmode': retmode\n",
    "    }\n",
    "    \n",
    "    filename = os.path.join(db, str(article_id))\n",
    "    if (os.path.exists(filename)) and (not refresh):\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "            response = requests.get(url=url_fetch, headers=headers, params=params)\n",
    "        except requests.RequestException:\n",
    "            print('Problem has occured with PMC ID: {0}'.format(article_id))\n",
    "        else:\n",
    "            data = response.text\n",
    "            with open(filename, 'w+', encoding='utf-8') as f:\n",
    "                f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T12:52:34.832463Z",
     "start_time": "2020-07-28T12:52:34.813648Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_all_query_responses(query, db, refresh=False):\n",
    "    \"\"\"Downloads all query responses got by <query>\"\"\"\n",
    "    article_ids = get_article_ids(query, db)\n",
    "    \n",
    "    article_ids = [str(article_id) for article_id in article_ids]\n",
    "    files_list = os.listdir(db)\n",
    "    intersection = list(set(article_ids) & set(files_list))\n",
    "    \n",
    "    print('{0} articles found in {1} with query specified.'.format(len(article_ids), db))\n",
    "    print('{0} articles are already stored in the database.'.format(len(intersection)))\n",
    "    print('{0} articles will be downloaded.'.format(len(article_ids) - len(intersection)))\n",
    "    \n",
    "    for article_id in article_ids:\n",
    "        download_query_response(article_id, db, refresh)\n",
    "    \n",
    "    files_count = len(os.listdir(db))\n",
    "    print('Total {0} articles stored in the database.'.format(files_count))\n",
    "    return article_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Neurosurgery articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T12:52:35.973089Z",
     "start_time": "2020-07-28T12:52:35.960385Z"
    }
   },
   "outputs": [],
   "source": [
    "db = 'pubmed'\n",
    "query = 'text classification neural network'\n",
    "query1 = '(neurosurg*) AND (complicat*[Text Word])'\n",
    "query2 = '(\"Glioma/surgery\"[Mesh] OR \"Glioma/therapy\"[Mesh])'\n",
    "query3 = '(\"Neurosurgery\"[Mesh] OR \"Neurosurgical Procedures\"[Mesh]) AND \"Postoperative Complications\"[Mesh]'\n",
    "query4 = '(\"Neurosurgery\"[Mesh] OR \"Neurosurgical Procedures\"[Mesh]) AND complicat*[Text Word]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T13:18:03.188758Z",
     "start_time": "2020-07-28T13:18:01.772951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232 articles found in pubmed with query specified.\n",
      "232 articles are already stored in the database.\n",
      "0 articles will be downloaded.\n",
      "Total 235 articles stored in the database.\n"
     ]
    }
   ],
   "source": [
    "article_ids = download_all_query_responses(query=query, db=db, refresh=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle query responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T14:00:29.329386Z",
     "start_time": "2020-07-28T14:00:20.503016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 232 of 232. Working on pubmed\\7949911\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>pmc</th>\n",
       "      <th>pii</th>\n",
       "      <th>mid</th>\n",
       "      <th>publisher-id</th>\n",
       "      <th>doi</th>\n",
       "      <th>abstract_len</th>\n",
       "      <th>file_size</th>\n",
       "      <th>title</th>\n",
       "      <th>article-type</th>\n",
       "      <th>...</th>\n",
       "      <th>issn_print</th>\n",
       "      <th>journal-id_nlm-ta</th>\n",
       "      <th>journal_title</th>\n",
       "      <th>journal_iso_abbr</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>publisher_loc</th>\n",
       "      <th>copyright</th>\n",
       "      <th>license-type</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32673791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S1532-0464(20)30139-8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1016/j.jbi.2020.103511</td>\n",
       "      <td>794</td>\n",
       "      <td>7644</td>\n",
       "      <td>An Attention-based Multi-Task Model for Named ...</td>\n",
       "      <td>pubmed_article</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Journal of biomedical informatics</td>\n",
       "      <td>J Biomed Inform</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In this paper, we propose an attention-based m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32590229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S1386-5056(19)31088-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1016/j.ijmedinf.2020.104225</td>\n",
       "      <td>1786</td>\n",
       "      <td>8217</td>\n",
       "      <td>Clinical questionnaire filling based on questi...</td>\n",
       "      <td>pubmed_article</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>International journal of medical informatics</td>\n",
       "      <td>Int J Med Inform</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BACKGROUND: Electronic Health Records (EHR) ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32584774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1109/TNNLS.2020.3002798</td>\n",
       "      <td>1976</td>\n",
       "      <td>6098</td>\n",
       "      <td>Automated Social Text Annotation With Joint Mu...</td>\n",
       "      <td>pubmed_article</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IEEE transactions on neural networks and learn...</td>\n",
       "      <td>IEEE Trans Neural Netw Learn Syst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Automated social text annotation is the task o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32570656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SHTI200439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.3233/SHTI200439</td>\n",
       "      <td>951</td>\n",
       "      <td>5973</td>\n",
       "      <td>Predicting Diagnosis Code from Medication List...</td>\n",
       "      <td>pubmed_article</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Studies in health technology and informatics</td>\n",
       "      <td>Stud Health Technol Inform</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Automated coding and classification systems pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32558750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1097/MAO.0000000000002710</td>\n",
       "      <td>2139</td>\n",
       "      <td>10105</td>\n",
       "      <td>Predicting Postoperative Cochlear Implant Perf...</td>\n",
       "      <td>pubmed_article</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Otology &amp; neurotology : official publication o...</td>\n",
       "      <td>Otol. Neurotol.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OBJECTIVES: To predict postoperative cochlear ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid  pmc                    pii  mid publisher-id  \\\n",
       "0  32673791  NaN  S1532-0464(20)30139-8  NaN          NaN   \n",
       "1  32590229  NaN  S1386-5056(19)31088-3  NaN          NaN   \n",
       "2  32584774  NaN                    NaN  NaN          NaN   \n",
       "3  32570656  NaN             SHTI200439  NaN          NaN   \n",
       "4  32558750  NaN                    NaN  NaN          NaN   \n",
       "\n",
       "                              doi abstract_len file_size  \\\n",
       "0       10.1016/j.jbi.2020.103511          794      7644   \n",
       "1  10.1016/j.ijmedinf.2020.104225         1786      8217   \n",
       "2      10.1109/TNNLS.2020.3002798         1976      6098   \n",
       "3              10.3233/SHTI200439          951      5973   \n",
       "4    10.1097/MAO.0000000000002710         2139     10105   \n",
       "\n",
       "                                               title    article-type  ...  \\\n",
       "0  An Attention-based Multi-Task Model for Named ...  pubmed_article  ...   \n",
       "1  Clinical questionnaire filling based on questi...  pubmed_article  ...   \n",
       "2  Automated Social Text Annotation With Joint Mu...  pubmed_article  ...   \n",
       "3  Predicting Diagnosis Code from Medication List...  pubmed_article  ...   \n",
       "4  Predicting Postoperative Cochlear Implant Perf...  pubmed_article  ...   \n",
       "\n",
       "  issn_print journal-id_nlm-ta  \\\n",
       "0        NaN               NaN   \n",
       "1        NaN               NaN   \n",
       "2        NaN               NaN   \n",
       "3        NaN               NaN   \n",
       "4        NaN               NaN   \n",
       "\n",
       "                                       journal_title  \\\n",
       "0                  Journal of biomedical informatics   \n",
       "1       International journal of medical informatics   \n",
       "2  IEEE transactions on neural networks and learn...   \n",
       "3       Studies in health technology and informatics   \n",
       "4  Otology & neurotology : official publication o...   \n",
       "\n",
       "                    journal_iso_abbr publisher_name publisher_loc copyright  \\\n",
       "0                    J Biomed Inform            NaN           NaN       NaN   \n",
       "1                   Int J Med Inform            NaN           NaN       NaN   \n",
       "2  IEEE Trans Neural Netw Learn Syst            NaN           NaN       NaN   \n",
       "3         Stud Health Technol Inform            NaN           NaN       NaN   \n",
       "4                    Otol. Neurotol.            NaN           NaN       NaN   \n",
       "\n",
       "  license-type license                                           abstract  \n",
       "0          NaN     NaN  In this paper, we propose an attention-based m...  \n",
       "1          NaN     NaN  BACKGROUND: Electronic Health Records (EHR) ar...  \n",
       "2          NaN     NaN  Automated social text annotation is the task o...  \n",
       "3          NaN     NaN  Automated coding and classification systems pl...  \n",
       "4          NaN     NaN  OBJECTIVES: To predict postoperative cochlear ...  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = handle_query_responses(db, article_ids)\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T14:16:38.293336Z",
     "start_time": "2020-07-28T14:16:38.269046Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 232 entries, 0 to 231\n",
      "Data columns (total 29 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   pmid               232 non-null    object\n",
      " 1   pmc                95 non-null     object\n",
      " 2   pii                138 non-null    object\n",
      " 3   mid                20 non-null     object\n",
      " 4   publisher-id       0 non-null      object\n",
      " 5   doi                223 non-null    object\n",
      " 6   abstract_len       232 non-null    object\n",
      " 7   file_size          232 non-null    object\n",
      " 8   title              232 non-null    object\n",
      " 9   article-type       232 non-null    object\n",
      " 10  category           0 non-null      object\n",
      " 11  authors            0 non-null      object\n",
      " 12  pub_date           232 non-null    object\n",
      " 13  keywords           0 non-null      object\n",
      " 14  volume             221 non-null    object\n",
      " 15  elocation-id       0 non-null      object\n",
      " 16  issue              146 non-null    object\n",
      " 17  pages              0 non-null      object\n",
      " 18  issn_electronic    189 non-null    object\n",
      " 19  issn_print         40 non-null     object\n",
      " 20  journal-id_nlm-ta  0 non-null      object\n",
      " 21  journal_title      232 non-null    object\n",
      " 22  journal_iso_abbr   232 non-null    object\n",
      " 23  publisher_name     0 non-null      object\n",
      " 24  publisher_loc      0 non-null      object\n",
      " 25  copyright          0 non-null      object\n",
      " 26  license-type       0 non-null      object\n",
      " 27  license            0 non-null      object\n",
      " 28  abstract           232 non-null    object\n",
      "dtypes: object(29)\n",
      "memory usage: 52.7+ KB\n"
     ]
    }
   ],
   "source": [
    "items.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:43:58.566796Z",
     "start_time": "2019-12-03T05:43:30.917314Z"
    }
   },
   "outputs": [],
   "source": [
    "items.to_csv('database/pmc_all.csv', sep='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T09:43:47.650352Z",
     "start_time": "2020-07-18T09:43:47.639202Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article-type': 'book',\n",
       " 'pmid': '32644742',\n",
       " 'title': 'Subacute Combined Degeneration of the Spinal Cord',\n",
       " 'abstract_structured': False,\n",
       " 'abstract': 'Subacute combined degeneration of the spinal cord is a neurological complication of vitamin B12 (cobalamin) deficiency. A deficiency of vitamin B12 can occur as a result of nutritional deficiency, reduced absorption due to altered gastrointestinal anatomy or function, or due to the intake of certain drugs. Subacute combined degeneration is characterized by degeneration of the dorsal columns and the lateral columns of the spinal cord due to demyelination. It commonly presents with sensory deficits, paresthesia, weakness, ataxia, and gait disturbance. In severe untreated cases, it can lead to spasticity and paraplegia. It is crucial to promptly identify and treat vitamin B12 deficiency to prevent the development of this serious neurological complication.',\n",
       " 'abstract_len': 762}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'pubmed/32644742'\n",
    "root = get_element_tree(filename)\n",
    "item = {}\n",
    "parse_element_tree_pubmed(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T07:46:56.572215Z",
     "start_time": "2020-07-16T07:46:56.565241Z"
    }
   },
   "outputs": [],
   "source": [
    "article_meta = root.find('PubmedArticle/MedlineCitation/Article')\n",
    "#root.find('PubmedArticle/MedlineCitation/Article/ArticleTitle').text\n",
    "pubmed_data = root.find('PubmedArticle/PubmedData')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
