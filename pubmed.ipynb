{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T09:00:46.076460Z",
     "start_time": "2020-07-17T09:00:45.709171Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T09:00:47.066861Z",
     "start_time": "2020-07-17T09:00:46.081226Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T09:00:59.031855Z",
     "start_time": "2020-07-17T09:00:59.016724Z"
    }
   },
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla / 5.0(Windows NT 10.0; Win64; x64) AppleWebKit / 537.36(KHTML, like Gecko) Chrome / 69.0.3497.81 Safari / 537.36'\n",
    "}\n",
    "\n",
    "api_key = '2839ed49187b099ec3d13cc079fc3ca0fc09'\n",
    "max_results = 5000\n",
    "retmode = 'xml'\n",
    "\n",
    "dbs = ['pmc', 'pubmed', 'database']\n",
    "for db in dbs:\n",
    "    if not os.path.exists(db):\n",
    "        os.makedirs(db)\n",
    "\n",
    "files_stoplist = ['6796246', '4669991', '4212306', '4070603', '4912513', '2799065', '5042924', '6032109', '5042923',\n",
    "                  '6555104', '5724662', '5493079', '6117636', '5933288', '6763540', '6493311', '6737605', '5637785']\n",
    "\n",
    "url_pubmed_to_pmc = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi'\n",
    "url_fetch = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi'\n",
    "url_search = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T09:01:02.855872Z",
     "start_time": "2020-07-17T09:01:02.845397Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_pub_date(subroot, pub_type):\n",
    "    \"\"\"Returns parsed publication date from given ET <subroot>\"\"\"\n",
    "    pub_date = np.NaN\n",
    "    pub_dates = subroot.findall('pub-date')\n",
    "    for pub_record in pub_dates:\n",
    "        if (pub_record.attrib.get('pub-type', '') == pub_type or\n",
    "            pub_record.attrib.get('date-type', '') == 'pub'):\n",
    "            day = pub_record.find('day')\n",
    "            month = pub_record.find('month')\n",
    "            year = pub_record.find('year')\n",
    "            if year is not None:\n",
    "                pub_date = year.text\n",
    "                if month is not None:\n",
    "                    pub_date += '-' + month.text\n",
    "                    if day is not None:\n",
    "                        pub_date += '-' + day.text\n",
    "    if pub_date is np.NaN:\n",
    "        pub_date = parse_pub_date(subroot, 'ppub')\n",
    "    return pub_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T09:01:03.438992Z",
     "start_time": "2020-07-17T09:01:03.421243Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_authors(subroot, path):\n",
    "    \"\"\"Returns parsed authors string from given ET <subroot>\"\"\"\n",
    "    authors = []\n",
    "    contributors = subroot.findall(path)\n",
    "    for contributor in contributors:\n",
    "        for contributor_meta in contributor.iter('name'):\n",
    "            surname = contributor_meta.find('surname')\n",
    "            given_name = contributor_meta.find('given-names')\n",
    "            if (surname is not None) and (given_name is not None):\n",
    "                surname = surname.text if surname.text is not None else ''\n",
    "                given_name = given_name.text if given_name.text is not None else ''\n",
    "                authors.append(' '.join([given_name, surname]))\n",
    "    if len(authors) > 0:\n",
    "        authors = ', '.join(authors)\n",
    "        authors = ' '.join(authors.split())\n",
    "    if authors:\n",
    "        return authors\n",
    "    return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T09:01:03.690847Z",
     "start_time": "2020-07-17T09:01:03.683251Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_keywords(subroot):\n",
    "    \"\"\"Returns parsed keywords string from given ET <subroot>\"\"\"\n",
    "    keywords = []\n",
    "    kwds = subroot.find('kwd-group')\n",
    "    if kwds is not None:\n",
    "        for kwd in kwds.iter('kwd'):\n",
    "            if kwd is not None and kwd.text is not None:\n",
    "                keywords.append(kwd.text)\n",
    "    if len(keywords) > 0:\n",
    "        keywords = '; '.join(keywords)\n",
    "        return keywords\n",
    "    return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T09:01:03.972491Z",
     "start_time": "2020-07-17T09:01:03.958083Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_issue(subroot):\n",
    "    \"\"\"Returns parsed journal issue dict from given ET <subroot>\"\"\"\n",
    "    journal_issue = {}\n",
    "    volume = subroot.find('volume')                            # Volume\n",
    "    if volume is not None:\n",
    "        journal_issue['volume'] = volume.text\n",
    "        \n",
    "    elocation_id = subroot.find('elocation-id')                # Elocation-id\n",
    "    if elocation_id is not None:\n",
    "        journal_issue['elocation-id'] = elocation_id.text\n",
    "        \n",
    "    issue = subroot.find('issue')                              # Issue\n",
    "    if issue is not None:\n",
    "        journal_issue['issue'] = issue.text\n",
    "        \n",
    "    fpage = subroot.find('fpage')                              # Pages\n",
    "    fpage = fpage.text if fpage is not None else None\n",
    "    lpage = subroot.find('lpage')\n",
    "    lpage = lpage.text if lpage is not None else None\n",
    "    \n",
    "    if isinstance(fpage, str) and isinstance(lpage, str):\n",
    "        journal_issue['pages'] = '-'.join([fpage, lpage])\n",
    "        \n",
    "    return journal_issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T09:01:04.298641Z",
     "start_time": "2020-07-17T09:01:04.274472Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_journal_meta(subroot, path):\n",
    "    \"\"\"Returns parsed journal meta dict from given ET <subroot>\"\"\"\n",
    "    journal_meta = {}\n",
    "    meta = subroot.find(path)\n",
    "    if meta is not None:\n",
    "        journal_ids = meta.findall('journal-id')                                            # Journal ids\n",
    "        for journal_id in journal_ids:\n",
    "            journal_meta['journal-id_' + journal_id.attrib.get('journal-id-type')] = journal_id.text\n",
    "            \n",
    "        issns = meta.findall('issn')                                                        # ISSNs\n",
    "        for issn in issns:\n",
    "            journal_meta['issn_' + issn.attrib.get('pub-type')] = issn.text\n",
    "        \n",
    "        journal_title = meta.find('journal-title-group/journal-title')                      # Journal title\n",
    "        if (journal_title is not None) and (journal_title.text is not None):\n",
    "            journal_meta['journal_title'] = journal_title.text\n",
    "            \n",
    "        publisher = meta.find('publisher')                                                  # Publisher\n",
    "        if publisher is not None:\n",
    "            publisher_name = publisher.find('publisher-name')                               # Publisher's name\n",
    "            if (publisher_name is not None) and (publisher_name.text is not None):\n",
    "                journal_meta['publisher_name'] = publisher_name.text\n",
    "                \n",
    "            publisher_loc = publisher.find('publisher-loc')                                 # Publisher's location\n",
    "            if (publisher_loc is not None) and (publisher_loc.text is not None):\n",
    "                journal_meta['publisher_loc'] = publisher_loc.text\n",
    "    return journal_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T09:01:04.574397Z",
     "start_time": "2020-07-17T09:01:04.566317Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_text(subroot, path):\n",
    "    \"\"\"Returns extracted text between xml tags\"\"\"\n",
    "    text = ''\n",
    "    section = subroot.find(path)\n",
    "    if section is not None:\n",
    "        for element in section.iter():\n",
    "            if element.text:\n",
    "                text = text + element.text + ' '\n",
    "            if element.tail:\n",
    "                text = text + element.tail + ' '\n",
    "        text = ' '.join(text.split())\n",
    "    if text:\n",
    "        return text\n",
    "    return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T09:01:05.154991Z",
     "start_time": "2020-07-17T09:01:05.135422Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_element_tree_pmc(root):\n",
    "    \"\"\"Returns parsed dict with all values found\"\"\"\n",
    "    item = {}\n",
    "    \n",
    "    item['article-type'] = root.find('article').get('article-type')                             # Article type\n",
    "    article_meta = root.findall('article/front/article-meta')                                   # Article meta\n",
    "    for meta in article_meta:\n",
    "        article_ids = meta.findall('article-id')                                                # Article ids\n",
    "        for article_id in article_ids:\n",
    "            item[article_id.get('pub-id-type')] = article_id.text\n",
    "            \n",
    "        category = meta.find('article-categories/subj-group/subject')                           # Article category\n",
    "        if category is not None:\n",
    "            item['category'] = category.text\n",
    "            \n",
    "        item['title'] = extract_text(meta, 'title-group/article-title')                         # Article title\n",
    "        item['authors'] = parse_authors(meta, 'contrib-group/contrib')                          # Authors\n",
    "        item['pub_date'] = parse_pub_date(meta, 'epub')                                         # Publication date\n",
    "    \n",
    "        copyright = meta.find('permissions/copyright-statement')                                # Copyright statement\n",
    "        if copyright is not None:\n",
    "            item['copyright'] = copyright.text\n",
    "        license_type = meta.find('permissions/license')                                         # License type\n",
    "        if license_type is not None:\n",
    "            item['license-type'] = license_type.get('license-type')\n",
    "        item['license'] = extract_text(meta, 'permissions/license/license-p')                   # License text\n",
    "        \n",
    "        item['keywords'] = parse_keywords(meta)                                                 # Keywords\n",
    "        item['abstract'] = extract_text(meta, 'abstract')                                       # Abstract\n",
    "        item.update(parse_issue(meta))                                                          # Journal issue\n",
    "    \n",
    "    item.update(parse_journal_meta(root, 'article/front/journal-meta'))                         # Journal meta\n",
    "    item['full_text'] = extract_text(root, 'article/body')\n",
    "    item['abstract_len'] = len(item['abstract']) if item['abstract'] is not np.NaN else 0\n",
    "    item['full_text_len'] = len(item['full_text']) if item['full_text'] is not np.NaN else 0\n",
    "            \n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T09:01:05.781622Z",
     "start_time": "2020-07-17T09:01:05.763960Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_element_tree_pubmed(root):\n",
    "    \"\"\"Returns parsed dict with all values found\"\"\"\n",
    "    item = {}\n",
    "    \n",
    "    pubmed_data = root.find('PubmedArticle/PubmedData')\n",
    "    article_meta = root.find('PubmedArticle/MedlineCitation/Article')\n",
    "    \n",
    "    article_ids = pubmed_data.findall('ArticleIdList/ArticleId')                                # Article ids\n",
    "    if article_ids is not None:\n",
    "        for article_id in article_ids:\n",
    "            if article_id.get('IdType') == 'pubmed':\n",
    "                item['pmid'] = article_id.text\n",
    "            else:\n",
    "                item[article_id.get('IdType')] = article_id.text\n",
    "    \n",
    "    title = article_meta.find('ArticleTitle')                                                   # Title\n",
    "    if title is not None:\n",
    "        item['title'] = title.text\n",
    "        \n",
    "    abstract = article_meta.find('Abstract/AbstractText')                                       # Abstract\n",
    "    if abstract is not None:\n",
    "        item['abstract'] = abstract.text\n",
    "    else:\n",
    "        item['abstract'] = np.NaN\n",
    "        \n",
    "    item['abstract_len'] = len(item['abstract']) if item['abstract'] is not np.NaN else 0\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T09:01:06.730490Z",
     "start_time": "2020-07-17T09:01:06.718596Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_element_tree(filename):\n",
    "    \"\"\"Returns parsed ElementTree object of an article with <pmc_id> identifier\"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        return None\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        data = f.read()        \n",
    "    root = ET.fromstring(data)\n",
    "    \n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T09:01:07.456250Z",
     "start_time": "2020-07-17T09:01:07.442166Z"
    }
   },
   "outputs": [],
   "source": [
    "def handle_query_responses(db, article_ids):\n",
    "    \"\"\"Returns articles DataFrame\"\"\"\n",
    "    filenames = [os.path.join(db, str(article_id)) for article_id in article_ids]\n",
    "    print('{0} query responses found. Starting...'.format(len(filenames)))\n",
    "    time.sleep(1)\n",
    "    \n",
    "    items = pd.DataFrame(columns=['pmid', 'pmc', 'publisher-id', 'doi', 'abstract_len', 'full_text_len', 'file_size',\n",
    "                                  'title', 'article-type', 'category', 'authors', 'pub_date', 'keywords',\n",
    "                                  'volume', 'elocation-id', 'issue', 'pages', 'issn_epub', 'issn_ppub',\n",
    "                                  'journal-id_nlm-ta', 'journal_title', 'publisher_name', 'publisher_loc',\n",
    "                                  'copyright', 'license-type', 'license', 'abstract', 'full_text'])\n",
    "    for i in range(0, len(filenames)):\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        #if filenames[i] in files_stoplist:\n",
    "        #    continue\n",
    "        print('Done {0} of {1}. Working on {2}'.format(i+1, len(filenames), filenames[i]))\n",
    "        \n",
    "        root = get_element_tree(filenames[i])\n",
    "        if db == 'pmc':\n",
    "            item = parse_element_tree_pmc(root)\n",
    "        elif db == 'pubmed':\n",
    "            item = parse_element_tree_pubmed(root)\n",
    "        item['file_size'] = os.path.getsize(filenames[i])\n",
    "        items = items.append(item, ignore_index=True)\n",
    "        if i % 5000 == 0:\n",
    "            items.to_csv('database/pmc.csv', sep='|', index=False)\n",
    "        \n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T09:01:08.148661Z",
     "start_time": "2020-07-17T09:01:08.125185Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_article_ids(query, db):\n",
    "    \"\"\"Returns all article ids found by <query>\"\"\"\n",
    "    params = {\n",
    "        'db': db,\n",
    "        'api_key': api_key,\n",
    "        'term': query,\n",
    "        'retmax': max_results,\n",
    "        'retstart': 0,\n",
    "        'retmode': retmode\n",
    "    }\n",
    "    article_ids = []\n",
    "    count = params['retmax'] + 1\n",
    "    \n",
    "    while params['retstart'] < count:\n",
    "        try:\n",
    "            response = requests.get(url=url_search, headers=headers, params=params)\n",
    "        except requests.RequestException:\n",
    "            print('Problem has occured at retstart: {0}'.format(params['retstart']))\n",
    "        else:\n",
    "            root = ET.fromstring(response.text)\n",
    "            for article_id in root.iter('Id'):\n",
    "                article_ids.append(int(article_id.text))\n",
    "            count = int(root.find('Count').text)\n",
    "        finally:\n",
    "            params['retstart'] += params['retmax']\n",
    "\n",
    "    return article_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T09:01:09.355608Z",
     "start_time": "2020-07-17T09:01:09.338503Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_query_response(article_id, db, refresh=False):\n",
    "    \"\"\"Saves article query response with <article_id> identifier to file\"\"\"\n",
    "    params = {\n",
    "        'db': db,\n",
    "        'id': article_id,\n",
    "        'api_key': api_key,\n",
    "        'retmode': retmode\n",
    "    }\n",
    "    \n",
    "    filename = os.path.join(db, str(article_id))\n",
    "    if (os.path.exists(filename)) and (not refresh):\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "            response = requests.get(url=url_fetch, headers=headers, params=params)\n",
    "        except requests.RequestException:\n",
    "            print('Problem has occured with PMC ID: {0}'.format(article_id))\n",
    "        else:\n",
    "            data = response.text\n",
    "            with open(filename, 'w+', encoding='utf-8') as f:\n",
    "                f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T09:49:31.448839Z",
     "start_time": "2020-07-17T09:49:31.432601Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_all_query_responses(query, db, refresh=False):\n",
    "    \"\"\"Downloads all query responses got by <query>\"\"\"\n",
    "    article_ids = get_article_ids(query, db)\n",
    "    \n",
    "    article_ids = [str(article_id) for article_id in article_ids]\n",
    "    files_list = os.listdir(db)\n",
    "    intersection = list(set(article_ids) & set(files_list))\n",
    "    \n",
    "    print('{0} articles found in {1} with query specified.'.format(len(article_ids), db))\n",
    "    print('{0} articles are already stored in the database.'.format(len(intersection)))\n",
    "    print('{0} articles will be downloaded.'.format(len(article_ids) - len(intersection)))\n",
    "    \n",
    "    for article_id in article_ids:\n",
    "        download_query_response(article_id, db, refresh)\n",
    "    \n",
    "    files_count = len(os.listdir(db))\n",
    "    print('Total {0} articles stored in the database'.format(files_count))\n",
    "    return article_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Neurosurgery articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T09:49:34.056088Z",
     "start_time": "2020-07-17T09:49:33.027489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232 articles found in pubmed with query specified.\n",
      "232 articles are already stored in the database.\n",
      "0 articles will be downloaded.\n",
      "Total 232 articles stored in the database\n"
     ]
    }
   ],
   "source": [
    "db = 'pubmed'\n",
    "query = 'text classification neural network'\n",
    "article_ids = download_all_query_responses(query=query, db=db, refresh=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle query responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T12:20:11.538172Z",
     "start_time": "2020-07-16T12:20:01.224501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 231 of 231. Working on pubmed\\7949911\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>pmc</th>\n",
       "      <th>publisher-id</th>\n",
       "      <th>doi</th>\n",
       "      <th>abstract_len</th>\n",
       "      <th>full_text_len</th>\n",
       "      <th>file_size</th>\n",
       "      <th>title</th>\n",
       "      <th>article-type</th>\n",
       "      <th>category</th>\n",
       "      <th>...</th>\n",
       "      <th>journal_title</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>publisher_loc</th>\n",
       "      <th>copyright</th>\n",
       "      <th>license-type</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>full_text</th>\n",
       "      <th>pii</th>\n",
       "      <th>mid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32590229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1016/j.ijmedinf.2020.104225</td>\n",
       "      <td>450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8217</td>\n",
       "      <td>Clinical questionnaire filling based on questi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Electronic Health Records (EHR) are the founda...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S1386-5056(19)31088-3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32584774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1109/TNNLS.2020.3002798</td>\n",
       "      <td>1980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6098</td>\n",
       "      <td>Automated Social Text Annotation With Joint Mu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Automated social text annotation is the task o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32570656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.3233/SHTI200439</td>\n",
       "      <td>951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5973</td>\n",
       "      <td>Predicting Diagnosis Code from Medication List...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Automated coding and classification systems pl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SHTI200439</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32558750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1097/MAO.0000000000002710</td>\n",
       "      <td>147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10105</td>\n",
       "      <td>Predicting Postoperative Cochlear Implant Perf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To predict postoperative cochlear implant perf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32547807</td>\n",
       "      <td>PMC7278512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.4258/hir.2020.26.2.104</td>\n",
       "      <td>392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12809</td>\n",
       "      <td>Analysis of Adverse Drug Reactions Identified ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Electronic Health Records (EHRs)-based surveil...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hir-26-2-104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid         pmc publisher-id                             doi  \\\n",
       "0  32590229         NaN          NaN  10.1016/j.ijmedinf.2020.104225   \n",
       "1  32584774         NaN          NaN      10.1109/TNNLS.2020.3002798   \n",
       "2  32570656         NaN          NaN              10.3233/SHTI200439   \n",
       "3  32558750         NaN          NaN    10.1097/MAO.0000000000002710   \n",
       "4  32547807  PMC7278512          NaN       10.4258/hir.2020.26.2.104   \n",
       "\n",
       "  abstract_len full_text_len file_size  \\\n",
       "0          450           NaN      8217   \n",
       "1         1980           NaN      6098   \n",
       "2          951           NaN      5973   \n",
       "3          147           NaN     10105   \n",
       "4          392           NaN     12809   \n",
       "\n",
       "                                               title article-type category  \\\n",
       "0  Clinical questionnaire filling based on questi...          NaN      NaN   \n",
       "1  Automated Social Text Annotation With Joint Mu...          NaN      NaN   \n",
       "2  Predicting Diagnosis Code from Medication List...          NaN      NaN   \n",
       "3  Predicting Postoperative Cochlear Implant Perf...          NaN      NaN   \n",
       "4  Analysis of Adverse Drug Reactions Identified ...          NaN      NaN   \n",
       "\n",
       "   ... journal_title publisher_name publisher_loc copyright license-type  \\\n",
       "0  ...           NaN            NaN           NaN       NaN          NaN   \n",
       "1  ...           NaN            NaN           NaN       NaN          NaN   \n",
       "2  ...           NaN            NaN           NaN       NaN          NaN   \n",
       "3  ...           NaN            NaN           NaN       NaN          NaN   \n",
       "4  ...           NaN            NaN           NaN       NaN          NaN   \n",
       "\n",
       "  license                                           abstract full_text  \\\n",
       "0     NaN  Electronic Health Records (EHR) are the founda...       NaN   \n",
       "1     NaN  Automated social text annotation is the task o...       NaN   \n",
       "2     NaN  Automated coding and classification systems pl...       NaN   \n",
       "3     NaN  To predict postoperative cochlear implant perf...       NaN   \n",
       "4     NaN  Electronic Health Records (EHRs)-based surveil...       NaN   \n",
       "\n",
       "                     pii  mid  \n",
       "0  S1386-5056(19)31088-3  NaN  \n",
       "1                    NaN  NaN  \n",
       "2             SHTI200439  NaN  \n",
       "3                    NaN  NaN  \n",
       "4           hir-26-2-104  NaN  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = handle_query_responses(db, article_ids)\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T12:20:27.613098Z",
     "start_time": "2020-07-16T12:20:27.578492Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 231 entries, 0 to 230\n",
      "Data columns (total 30 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   pmid               231 non-null    object\n",
      " 1   pmc                95 non-null     object\n",
      " 2   publisher-id       0 non-null      object\n",
      " 3   doi                222 non-null    object\n",
      " 4   abstract_len       231 non-null    object\n",
      " 5   full_text_len      0 non-null      object\n",
      " 6   file_size          231 non-null    object\n",
      " 7   title              231 non-null    object\n",
      " 8   article-type       0 non-null      object\n",
      " 9   category           0 non-null      object\n",
      " 10  authors            0 non-null      object\n",
      " 11  pub_date           0 non-null      object\n",
      " 12  keywords           0 non-null      object\n",
      " 13  volume             0 non-null      object\n",
      " 14  elocation-id       0 non-null      object\n",
      " 15  issue              0 non-null      object\n",
      " 16  pages              0 non-null      object\n",
      " 17  issn_epub          0 non-null      object\n",
      " 18  issn_ppub          0 non-null      object\n",
      " 19  journal-id_nlm-ta  0 non-null      object\n",
      " 20  journal_title      0 non-null      object\n",
      " 21  publisher_name     0 non-null      object\n",
      " 22  publisher_loc      0 non-null      object\n",
      " 23  copyright          0 non-null      object\n",
      " 24  license-type       0 non-null      object\n",
      " 25  license            0 non-null      object\n",
      " 26  abstract           230 non-null    object\n",
      " 27  full_text          0 non-null      object\n",
      " 28  pii                137 non-null    object\n",
      " 29  mid                20 non-null     object\n",
      "dtypes: object(30)\n",
      "memory usage: 54.3+ KB\n"
     ]
    }
   ],
   "source": [
    "items.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:43:58.566796Z",
     "start_time": "2019-12-03T05:43:30.917314Z"
    }
   },
   "outputs": [],
   "source": [
    "items.to_csv('database/pmc_all.csv', sep='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T07:46:20.846906Z",
     "start_time": "2020-07-16T07:46:20.834997Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'pubmed/7949911'\n",
    "root = get_element_tree(filename)\n",
    "item = {}\n",
    "parse_element_tree_pubmed(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T07:46:56.572215Z",
     "start_time": "2020-07-16T07:46:56.565241Z"
    }
   },
   "outputs": [],
   "source": [
    "article_meta = root.find('PubmedArticle/MedlineCitation/Article')\n",
    "#root.find('PubmedArticle/MedlineCitation/Article/ArticleTitle').text\n",
    "pubmed_data = root.find('PubmedArticle/PubmedData')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
